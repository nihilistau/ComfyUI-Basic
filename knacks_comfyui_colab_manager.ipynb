{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9YeBsrfbTbV8"
      },
      "source": [
        "Git clone the repo and install the requirements. (ignore the pip errors about protobuf)\n",
        "\n",
        "## **ComfyUI Enviroment**\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bbbbbbbbbb",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title Setup The Enviroment\n",
        "# #@title Environment Setup\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "OPTIONS = {}\n",
        "\n",
        "USE_GOOGLE_DRIVE = True  #@param {type:\"boolean\"}\n",
        "UPDATE_COMFY_UI = False  #@param {type:\"boolean\"}\n",
        "USE_COMFYUI_MANAGER = True  #@param {type:\"boolean\"}\n",
        "INSTALL_CUSTOM_NODES_DEPENDENCIES = True  #@param {type:\"boolean\"}\n",
        "OPTIONS['USE_GOOGLE_DRIVE'] = USE_GOOGLE_DRIVE\n",
        "OPTIONS['UPDATE_COMFY_UI'] = UPDATE_COMFY_UI\n",
        "OPTIONS['USE_COMFYUI_MANAGER'] = USE_COMFYUI_MANAGER\n",
        "OPTIONS['INSTALL_CUSTOM_NODES_DEPENDENCIES'] = INSTALL_CUSTOM_NODES_DEPENDENCIES\n",
        "\n",
        "current_dir = !pwd\n",
        "WORKSPACE = f\"{current_dir[0]}/ComfyUI\"\n",
        "\n",
        "if OPTIONS['USE_GOOGLE_DRIVE']:\n",
        "    !echo \"Mounting Google Drive...\"\n",
        "    %cd /\n",
        "\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "    WORKSPACE = \"/content/drive/MyDrive/ComfyUI\"\n",
        "    %cd /content/drive/MyDrive\n",
        "\n",
        "![ ! -d $WORKSPACE ] && echo -= Initial setup ComfyUI =- && git clone https://github.com/comfyanonymous/ComfyUI\n",
        "%cd $WORKSPACE\n",
        "\n",
        "if OPTIONS['UPDATE_COMFY_UI']:\n",
        "  !echo -= Updating ComfyUI =-\n",
        "\n",
        "  # Correction of the issue of permissions being deleted on Google Drive.\n",
        "  ![ -f \".ci/nightly/update_windows/update_comfyui_and_python_dependencies.bat\" ] && chmod 755 .ci/nightly/update_windows/update_comfyui_and_python_dependencies.bat\n",
        "  ![ -f \".ci/nightly/windows_base_files/run_nvidia_gpu.bat\" ] && chmod 755 .ci/nightly/windows_base_files/run_nvidia_gpu.bat\n",
        "  ![ -f \".ci/update_windows/update_comfyui_and_python_dependencies.bat\" ] && chmod 755 .ci/update_windows/update_comfyui_and_python_dependencies.bat\n",
        "  ![ -f \".ci/update_windows_cu118/update_comfyui_and_python_dependencies.bat\" ] && chmod 755 .ci/update_windows_cu118/update_comfyui_and_python_dependencies.bat\n",
        "  ![ -f \".ci/update_windows/update.py\" ] && chmod 755 .ci/update_windows/update.py\n",
        "  ![ -f \".ci/update_windows/update_comfyui.bat\" ] && chmod 755 .ci/update_windows/update_comfyui.bat\n",
        "  ![ -f \".ci/update_windows/README_VERY_IMPORTANT.txt\" ] && chmod 755 .ci/update_windows/README_VERY_IMPORTANT.txt\n",
        "  ![ -f \".ci/update_windows/run_cpu.bat\" ] && chmod 755 .ci/update_windows/run_cpu.bat\n",
        "  ![ -f \".ci/update_windows/run_nvidia_gpu.bat\" ] && chmod 755 .ci/update_windows/run_nvidia_gpu.bat\n",
        "\n",
        "  !git pull\n",
        "\n",
        "!echo -= Install dependencies =-\n",
        "!pip3 install accelerate\n",
        "!pip3 install einops transformers>=4.28.1 safetensors>=0.4.2 aiohttp pyyaml Pillow scipy tqdm psutil tokenizers>=0.13.3\n",
        "!pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
        "!pip3 install torchsde\n",
        "!pip3 install kornia>=0.7.1 spandrel soundfile sentencepiece\n",
        "\n",
        "if OPTIONS['USE_COMFYUI_MANAGER']:\n",
        "  %cd custom_nodes\n",
        "\n",
        "  # Correction of the issue of permissions being deleted on Google Drive.\n",
        "  ![ -f \"ComfyUI-Manager/check.sh\" ] && chmod 755 ComfyUI-Manager/check.sh\n",
        "  ![ -f \"ComfyUI-Manager/scan.sh\" ] && chmod 755 ComfyUI-Manager/scan.sh\n",
        "  ![ -f \"ComfyUI-Manager/node_db/dev/scan.sh\" ] && chmod 755 ComfyUI-Manager/node_db/dev/scan.sh\n",
        "  ![ -f \"ComfyUI-Manager/node_db/tutorial/scan.sh\" ] && chmod 755 ComfyUI-Manager/node_db/tutorial/scan.sh\n",
        "  ![ -f \"ComfyUI-Manager/scripts/install-comfyui-venv-linux.sh\" ] && chmod 755 ComfyUI-Manager/scripts/install-comfyui-venv-linux.sh\n",
        "  ![ -f \"ComfyUI-Manager/scripts/install-comfyui-venv-win.bat\" ] && chmod 755 ComfyUI-Manager/scripts/install-comfyui-venv-win.bat\n",
        "\n",
        "  ![ ! -d ComfyUI-Manager ] && echo -= Initial setup ComfyUI-Manager =- && git clone https://github.com/ltdrdata/ComfyUI-Manager\n",
        "  %cd ComfyUI-Manager\n",
        "  !git pull\n",
        "\n",
        "%cd $WORKSPACE\n",
        "\n",
        "if OPTIONS['INSTALL_CUSTOM_NODES_DEPENDENCIES']:\n",
        "  !echo -= Install custom nodes dependencies =-\n",
        "  !pip install GitPython\n",
        "  !python custom_nodes/ComfyUI-Manager/cm-cli.py restore-dependencies\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model manager — prefilled Civitai downloads (comment/uncomment to use)\n",
        "\n",
        "Each block includes a title comment and any special notes (NSFW, login required). Use `CIVITAI_API_TOKEN` environment variable for API downloads. If a model requires web login or is private, you'll need to download via the browser or the Civitai web UI."
      ],
      "metadata": {
        "id": "kriPFxZuVbJ8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dddddddddd",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title Model Downloads\n",
        "from google.colab import userdata\n",
        "CIVITAI_API_TOKEN = userdata.get('CIVITAI_API_TOKEN')\n",
        "\n",
        "# Checkpoints\n",
        "\n",
        "### SDXL\n",
        "### I recommend these workflow examples: https://comfyanonymous.github.io/ComfyUI_examples/sdxl/\n",
        "\n",
        "#!wget -c https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0/resolve/main/sd_xl_base_1.0.safetensors -P ./models/checkpoints/\n",
        "#!wget -c https://huggingface.co/stabilityai/stable-diffusion-xl-refiner-1.0/resolve/main/sd_xl_refiner_1.0.safetensors -P ./models/checkpoints/\n",
        "\n",
        "# SDXL ReVision\n",
        "#!wget -c https://huggingface.co/comfyanonymous/clip_vision_g/resolve/main/clip_vision_g.safetensors -P ./models/clip_vision/\n",
        "\n",
        "# SD1.5\n",
        "!wget -c https://huggingface.co/runwayml/stable-diffusion-v1-5/resolve/main/v1-5-pruned-emaonly.ckpt -P ./models/checkpoints/\n",
        "\n",
        "# SD2\n",
        "#!wget -c https://huggingface.co/stabilityai/stable-diffusion-2-1-base/resolve/main/v2-1_512-ema-pruned.safetensors -P ./models/checkpoints/\n",
        "#!wget -c https://huggingface.co/stabilityai/stable-diffusion-2-1/resolve/main/v2-1_768-ema-pruned.safetensors -P ./models/checkpoints/\n",
        "\n",
        "# Some SD1.5 anime style\n",
        "#!wget -c https://huggingface.co/WarriorMama777/OrangeMixs/resolve/main/Models/AbyssOrangeMix2/AbyssOrangeMix2_hard.safetensors -P ./models/checkpoints/\n",
        "#!wget -c https://huggingface.co/WarriorMama777/OrangeMixs/resolve/main/Models/AbyssOrangeMix3/AOM3A1_orangemixs.safetensors -P ./models/checkpoints/\n",
        "#!wget -c https://huggingface.co/WarriorMama777/OrangeMixs/resolve/main/Models/AbyssOrangeMix3/AOM3A3_orangemixs.safetensors -P ./models/checkpoints/\n",
        "#!wget -c https://huggingface.co/Linaqruf/anything-v3.0/resolve/main/anything-v3-fp16-pruned.safetensors -P ./models/checkpoints/\n",
        "\n",
        "# Waifu Diffusion 1.5 (anime style SD2.x 768-v)\n",
        "#!wget -c https://huggingface.co/waifu-diffusion/wd-1-5-beta3/resolve/main/wd-illusion-fp16.safetensors -P ./models/checkpoints/\n",
        "\n",
        "\n",
        "# unCLIP models\n",
        "#!wget -c https://huggingface.co/comfyanonymous/illuminatiDiffusionV1_v11_unCLIP/resolve/main/illuminatiDiffusionV1_v11-unclip-h-fp16.safetensors -P ./models/checkpoints/\n",
        "#!wget -c https://huggingface.co/comfyanonymous/wd-1.5-beta2_unCLIP/resolve/main/wd-1-5-beta2-aesthetic-unclip-h-fp16.safetensors -P ./models/checkpoints/\n",
        "\n",
        "\n",
        "# VAE\n",
        "!wget -c https://huggingface.co/stabilityai/sd-vae-ft-mse-original/resolve/main/vae-ft-mse-840000-ema-pruned.safetensors -P ./models/vae/\n",
        "#!wget -c https://huggingface.co/WarriorMama777/OrangeMixs/resolve/main/VAEs/orangemix.vae.pt -P ./models/vae/\n",
        "#!wget -c https://huggingface.co/hakurei/waifu-diffusion-v1-4/resolve/main/vae/kl-f8-anime2.ckpt -P ./models/vae/\n",
        "\n",
        "\n",
        "# Loras\n",
        "#!wget -c https://civitai.com/api/download/models/10350 -O ./models/loras/theovercomer8sContrastFix_sd21768.safetensors #theovercomer8sContrastFix SD2.x 768-v\n",
        "#!wget -c https://civitai.com/api/download/models/10638 -O ./models/loras/theovercomer8sContrastFix_sd15.safetensors #theovercomer8sContrastFix SD1.x\n",
        "#!wget -c https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0/resolve/main/sd_xl_offset_example-lora_1.0.safetensors -P ./models/loras/ #SDXL offset noise lora\n",
        "\n",
        "\n",
        "# T2I-Adapter\n",
        "#!wget -c https://huggingface.co/TencentARC/T2I-Adapter/resolve/main/models/t2iadapter_depth_sd14v1.pth -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/TencentARC/T2I-Adapter/resolve/main/models/t2iadapter_seg_sd14v1.pth -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/TencentARC/T2I-Adapter/resolve/main/models/t2iadapter_sketch_sd14v1.pth -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/TencentARC/T2I-Adapter/resolve/main/models/t2iadapter_keypose_sd14v1.pth -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/TencentARC/T2I-Adapter/resolve/main/models/t2iadapter_openpose_sd14v1.pth -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/TencentARC/T2I-Adapter/resolve/main/models/t2iadapter_color_sd14v1.pth -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/TencentARC/T2I-Adapter/resolve/main/models/t2iadapter_canny_sd14v1.pth -P ./models/controlnet/\n",
        "\n",
        "# T2I Styles Model\n",
        "#!wget -c https://huggingface.co/TencentARC/T2I-Adapter/resolve/main/models/t2iadapter_style_sd14v1.pth -P ./models/style_models/\n",
        "\n",
        "# CLIPVision model (needed for styles model)\n",
        "#!wget -c https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/pytorch_model.bin -O ./models/clip_vision/clip_vit14.bin\n",
        "\n",
        "\n",
        "# ControlNet\n",
        "#!wget -c https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11e_sd15_ip2p_fp16.safetensors -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11e_sd15_shuffle_fp16.safetensors -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11p_sd15_canny_fp16.safetensors -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11f1p_sd15_depth_fp16.safetensors -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11p_sd15_inpaint_fp16.safetensors -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11p_sd15_lineart_fp16.safetensors -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11p_sd15_mlsd_fp16.safetensors -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11p_sd15_normalbae_fp16.safetensors -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11p_sd15_openpose_fp16.safetensors -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11p_sd15_scribble_fp16.safetensors -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11p_sd15_seg_fp16.safetensors -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11p_sd15_softedge_fp16.safetensors -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11p_sd15s2_lineart_anime_fp16.safetensors -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11u_sd15_tile_fp16.safetensors -P ./models/controlnet/\n",
        "\n",
        "# ControlNet SDXL\n",
        "#!wget -c https://huggingface.co/stabilityai/control-lora/resolve/main/control-LoRAs-rank256/control-lora-canny-rank256.safetensors -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/stabilityai/control-lora/resolve/main/control-LoRAs-rank256/control-lora-depth-rank256.safetensors -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/stabilityai/control-lora/resolve/main/control-LoRAs-rank256/control-lora-recolor-rank256.safetensors -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/stabilityai/control-lora/resolve/main/control-LoRAs-rank256/control-lora-sketch-rank256.safetensors -P ./models/controlnet/\n",
        "\n",
        "# Controlnet Preprocessor nodes by Fannovel16\n",
        "#!cd custom_nodes && git clone https://github.com/Fannovel16/comfy_controlnet_preprocessors; cd comfy_controlnet_preprocessors && python install.py\n",
        "\n",
        "\n",
        "# GLIGEN\n",
        "#!wget -c https://huggingface.co/comfyanonymous/GLIGEN_pruned_safetensors/resolve/main/gligen_sd14_textbox_pruned_fp16.safetensors -P ./models/gligen/\n",
        "\n",
        "\n",
        "# ESRGAN upscale model\n",
        "#!wget -c https://github.com/xinntao/Real-ESRGAN/releases/download/v0.1.0/RealESRGAN_x4plus.pth -P ./models/upscale_models/\n",
        "#!wget -c https://huggingface.co/sberbank-ai/Real-ESRGAN/resolve/main/RealESRGAN_x2.pth -P ./models/upscale_models/\n",
        "#!wget -c https://huggingface.co/sberbank-ai/Real-ESRGAN/resolve/main/RealESRGAN_x4.pth -P ./models/upscale_models/\n",
        "\n",
        "# XXX CivitAI\n",
        "\n",
        "# 1) Model ID 1624818 — SafeTensor API download (may require login)\n",
        "# wget pattern (SafeTensor fp16):\n",
        "# !wget \"https://civitai.com/api/download/models/1624818?type=Model&format=SafeTensor&size=full&fp=fp16&CIVITAI_TOKEN=$CIVITAI_API_TOKEN\" --content-disposition -P \"{LORAS_DIR}\"\n",
        "\n",
        "# 2) CyberRealistic Pony (ID 443821) — checkpoint (SafeTensor). See recommended settings in model page.\n",
        "# !wget \"https://civitai.com/api/download/models/443821?type=Model&format=SafeTensor&size=full&CIVITAI_TOKEN=$CIVITAI_API_TOKEN\" --content-disposition -P \"{MODELS_DIR}/cyberrealistic\"\n",
        "\n",
        "# 3) Doggy-Style (ID 1741501) — NSFW, login required. Use web UI if API returns login required.\n",
        "# (if available via API):\n",
        "# !wget \"https://civitai.com/api/download/models/1741501?type=Model&format=SafeTensor&size=full&CIVITAI_TOKEN=$CIVITAI_API_TOKEN\" --content-disposition -P \"{MODELS_DIR}/wan\"\n",
        "\n",
        "# 4) WAN POV Cowgirl insertion (ID 2048863) — NSFW\n",
        "# !wget \"https://civitai.com/api/download/models/2048863?type=Model&format=GGUF&size=full&CIVITAI_TOKEN=$CIVITAI_API_TOKEN\" --content-disposition -P \"{GGUF_DIR}\"\n",
        "\n",
        "# 5) QWEN-4 play LoRA (ID 2004155) — LoRA (may be LORA format). Check model page for exact file names and formats.\n",
        "# !wget \"https://civitai.com/api/download/models/2004155?type=Model&format=SafeTensor&size=full&CIVITAI_TOKEN=$CIVITAI_API_TOKEN\" --content-disposition -P \"{LORAS_DIR}\"\n",
        "\n",
        "# 6) WAN-22 I2V (ID 2031069) — NSFW video-capable model; may have GGUF or special instructions.\n",
        "# !wget \"https://civitai.com/api/download/models/2031069?type=Model&format=GGUF&size=full&CIVITAI_TOKEN=$CIVITAI_API_TOKEN\" --content-disposition -P \"{GGUF_DIR}\"\n",
        "\n",
        "# 7) PENIS LoRA / TAZ (ID 1476909) — NSFW LoRA. Login required for NSFW models on some pages.\n",
        "# !wget \"https://civitai.com/api/download/models/1476909?type=Model&format=SafeTensor&size=full&CIVITAI_TOKEN=$CIVITAI_API_TOKEN\" --content-disposition -P \"{LORAS_DIR}\"\n",
        "\n",
        "# 8) POV Insertion WAN 2x (ID 1855263) — NSFW, video/wan style.\n",
        "# !wget \"https://civitai.com/api/download/models/1855263?type=Model&format=GGUF&size=full&CIVITAI_TOKEN=$CIVITAI_API_TOKEN\" --content-disposition -P \"{GGUF_DIR}\"\n",
        "\n",
        "# 9) Oral Insertion WAN (ID 1874153) — NSFW\n",
        "# !wget \"https://civitai.com/api/download/models/1874153?type=Model&format=GGUF&size=full&CIVITAI_TOKEN=$CIVITAI_API_TOKEN\" --content-disposition -P \"{GGUF_DIR}\"\n",
        "\n",
        "# 10) WAN-2221 POV Missionary (ID 1331682) — NSFW\n",
        "# !wget \"https://civitai.com/api/download/models/1331682?type=Model&format=GGUF&size=full&CIVITAI_TOKEN=$CIVITAI_API_TOKEN\" --content-disposition -P \"{GGUF_DIR}\"\n",
        "\n",
        "# 11) CyberRealistic (ID 15003) — photorealistic SD base; recommended settings in page.\n",
        "# !wget \"https://civitai.com/api/download/models/15003?type=Model&format=SafeTensor&size=full&CIVITAI_TOKEN=$CIVITAI_API_TOKEN\" --content-disposition -P \"{MODELS_DIR}/cyberrealistic\"\n",
        "\n",
        "# 12) ChilloutMix (ID 6424) — popular blended model (may require SafeTensor format).\n",
        "# !wget \"https://civitai.com/api/download/models/6424?type=Model&format=SafeTensor&size=full&CIVITAI_TOKEN=$CIVITAI_API_TOKEN\" --content-disposition -P \"{MODELS_DIR}/chilloutmix\"\n",
        "\n",
        "# 13) WAN-22 Experimental (ID 1307155) — your provided WAN model link (GGUF/SafeTensor examples).\n",
        "# GGUF example (preferred for Wan2 runners):\n",
        "# !wget \"https://civitai.com/api/download/models/1307155?type=Model&format=GGUF&size=full&CIVITAI_TOKEN=$CIVITAI_API_TOKEN\" --content-disposition -P \"{GGUF_DIR}\"\n",
        "# Safetensor (alternate):\n",
        "# !wget \"https://civitai.com/api/download/models/1307155?type=Model&format=SafeTensor&size=full&fp=fp16&CIVITAI_TOKEN=$CIVITAI_API_TOKEN\" --content-disposition -P \"{MODELS_DIR}/wan\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Per-model metadata: Civitai model 652699 — 'Amateur Photography' LoRA\n",
        "# This model is a LoRA with recommended settings pulled from the model page where available.\n",
        "MODEL_652699 = {\n",
        "  'model_id': 652699,\n",
        "  'modelVersionId': 993999,\n",
        "  'type': 'LoRA',\n",
        "  'gated': False,\n",
        "  'download_template': f'!wget \"https://civitai.com/api/download/models/652699?modelVersionId=993999&format=SafeTensor&CIVITAI_TOKEN=$CIVITAI_API_TOKEN\" --content-disposition -P \"{{LORAS_DIR}}\"',\n",
        "  'recommended_settings': {\n",
        "    'distilled_cfg_scale': 3.5,\n",
        "    'sampler': 'DEIS with DDIM',\n",
        "    'steps': 20,\n",
        "    'resolution': '896x1152 or 880x1184 / 1328x1776',\n",
        "    'hires_fix_upscaler': '4x_NMKD-Superscale-SP_178000_G',\n",
        "    'hires_steps': 10,\n",
        "    'hires_denoise': 0.3,\n",
        "    'lora_weight': 0.8,\n",
        "    'usage_tip': 'Try EasyCache (skip 2 steps) for faster results with little quality loss.'\n",
        "  },\n",
        "  'notes': 'Typical use: apply this LoRA at ~0.8 weight during sampling / hi-res steps. Adjust per prompt.'\n",
        "}\n",
        "print('Model metadata for 652699 registered. Inspect MODEL_652699 for recommended settings.')\n",
        "\n",
        "# Example: to download after setting CIVITAI_API_TOKEN, copy and run MODEL_652699['download_template'] (uncomment).\n",
        "\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "uBWTJQpWpvVk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Per-model metadata: Civitai model 1064836 (user-supplied)\n",
        "# Guarded metadata and a download template. This model page is NSFW/gated — you may need to login or use the API token.\n",
        "MODEL_1064836 = {\n",
        "  'model_id': 1064836,\n",
        "  'modelVersionId': 993999,\n",
        "  'type': 'image/checkpoint',\n",
        "  'gated': True,\n",
        "  'notes': 'NSFW-gated content. If the API download fails, download via web UI and upload to Drive. Example settings may be on model page.' ,\n",
        "  'download_template': f'!wget \"https://civitai.com/api/download/models/1064836?modelVersionId=993999&format=SafeTensor&CIVITAI_TOKEN=$CIVITAI_API_TOKEN\" --content-disposition -P \"{{MODELS_DIR}}/model_1064836\"',\n",
        "  'recommended_settings': {},\n",
        "}\n",
        "print('Model metadata for 1064836 registered. Inspect MODEL_1064836 for download template and notes.')\n",
        "\n",
        "# Usage: if you set CIVITAI_API_TOKEN via the secure cell above, copy the download_template and run it (uncomment) to download."
      ],
      "metadata": {
        "cellView": "form",
        "id": "Q07PGTI6pzxm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ComfyUI Launcher — CloudFlare (Public CloudFlare TUNNEL)\n",
        "\n",
        "Loads a local comfyUI instance Creates a CloudFlare Tunnel that provides a\n",
        "random.domain.name.cloudflare.com\n",
        "\n",
        "The domain name will be shown in the output. Simply click the link."
      ],
      "metadata": {
        "id": "hD2HMLeMWFib"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RIYyWhk0TbV9"
      },
      "source": [
        "# Run ComfyUI VIA CloudFlare\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_rF4OMePTbV9",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title ComfyUI with cloudflared (Recommended Way)\n",
        "!wget https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64.deb\n",
        "!dpkg -i cloudflared-linux-amd64.deb\n",
        "\n",
        "import subprocess\n",
        "import threading\n",
        "import time\n",
        "import socket\n",
        "import urllib.request\n",
        "\n",
        "#me reqs\n",
        "!python3 -m pip install -r /content/drive/MyDrive/ComfyUI/requirements.txt\n",
        "\n",
        "def iframe_thread(port):\n",
        "  while True:\n",
        "      time.sleep(0.5)\n",
        "      sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
        "      result = sock.connect_ex(('127.0.0.1', port))\n",
        "      if result == 0:\n",
        "        break\n",
        "      sock.close()\n",
        "  print(\"\\nComfyUI finished loading, trying to launch cloudflared (if it gets stuck here cloudflared is having issues)\\n\")\n",
        "\n",
        "  p = subprocess.Popen([\"cloudflared\", \"tunnel\", \"--url\", \"http://127.0.0.1:{}\".format(port)], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
        "  for line in p.stderr:\n",
        "    l = line.decode()\n",
        "    if \"trycloudflare.com \" in l:\n",
        "      print(\"This is the URL to access ComfyUI:\", l[l.find(\"http\"):], end='')\n",
        "    #print(l, end='')\n",
        "\n",
        "\n",
        "threading.Thread(target=iframe_thread, daemon=True, args=(8188,)).start()\n",
        "\n",
        "!python main.py --dont-print-server"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "_mK5YlHEY61y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Copy Cloudflare public URL to clipboard\n",
        "import os\n",
        "from IPython.display import HTML, display\n",
        "url = os.environ.get('COMFYUI_PUBLIC_URL', '')\n",
        "if url:\n",
        "  display(HTML(f\"<input type='text' value='{url}' id='cfurl' style='width:400px' /><button onclick=\\\"navigator.clipboard.writeText(document.getElementById('cfurl').value)\\\">Copy</button>\"))\n",
        "else:\n",
        "  print('No COMFYUI_PUBLIC_URL set. Run the cloudflared cell first.')"
      ],
      "metadata": {
        "id": "947fPgkQZQhY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Stop cloudflared and ComfyUI (cleanup)\n",
        "import subprocess\n",
        "\n",
        "subprocess.run(['pkill', '-f', 'cloudflared'], check=False)\n",
        "subprocess.run(['pkill', '-f', 'main.py'], check=False)\n",
        "print('Termination signals sent. Ignore \"process not found\" warnings if services were already stopped.')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "LWZVpRtEOaib"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "5FU9EBKGY75Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "oo2NZ1aFZNy0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "8HCs0BafY6e_"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0fdf9462"
      },
      "source": [
        "## Advanced & Custom Workflows (model-tuned)\n",
        "\n",
        "This section contains richer ComfyUI flows tuned as starting points.. These flows are templates — open them in ComfyUI's Flow Editor and tweak sampler, steps, seed and LoRA weights to match your runtime and model specifics.\n",
        "\n",
        "Below are two saved example flows: an image-focused T2I flow tuned for photographic realism, and a Wan2.1-ready video workflow that uses image frames plus LoRA application for pose/placement.\n",
        "\n",
        "Each flow is saved into `DRIVE_ROOT/flows` (see the example save cell earlier). After you start ComfyUI, load these JSON files in the Flow Editor and wire any custom nodes present in your setup."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "0B4AV8NojtkY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Complex node helpers — generate ComfyUI node snippets and compose flows\n",
        "\"\"\"\n",
        "Provides helper functions to generate reusable node snippets and to compose a flow JSON\n",
        "compatible with ComfyUI's typical on-disk format (a minimal, widely-used subset).\n",
        "The composer supports two modes:\n",
        " - format='simple'  : legacy minimal list-of-nodes (backwards compatible)\n",
        " - format='comfyui' : produces a dict with 'nodes' mapping node-id -> node-dict\n",
        "\n",
        "The produced \"comfyui\" nodes use conventional node type names found in many ComfyUI flows\n",
        "(e.g. \"CLIPTextEncode\", \"CheckpointLoaderSimple\", \"KSampler\", \"LoraLoader\", \"SaveImage\",\n",
        "\"LatentUpscaler\"). These are widely compatible but you can tweak names to match your exact install.\n",
        "\"\"\"\n",
        "import json, time, os\n",
        "from pathlib import Path\n",
        "\n",
        "DRIVE_ROOT = globals().get('DRIVE_ROOT','/content/drive/MyDrive/ComfyUI')\n",
        "FLOWS_DIR = Path(DRIVE_ROOT)/'flows'\n",
        "FLOWS_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "_node_counter = 1000\n",
        "\n",
        "def _next_node_id():\n",
        "    global _node_counter\n",
        "    _node_counter += 1\n",
        "    return _node_counter\n",
        "\n",
        "# --- simple (previous) helper nodes (kept for backwards compatibility)\n",
        "\n",
        "def make_text_encoder_node(prompt):\n",
        "    nid = _next_node_id()\n",
        "    return {\n",
        "        'id': nid,\n",
        "        'type': 'TextEncoder',\n",
        "        'args': {'prompt': prompt}\n",
        "    }\n",
        "\n",
        "\n",
        "def make_sampler_node(sampler='DDIM', steps=20, seed=-1):\n",
        "    nid = _next_node_id()\n",
        "    return {\n",
        "        'id': nid,\n",
        "        'type': 'Sampler',\n",
        "        'args': {'sampler': sampler, 'steps': steps, 'seed': seed}\n",
        "    }\n",
        "\n",
        "\n",
        "def make_lora_node(lora_path, weight=0.8):\n",
        "    nid = _next_node_id()\n",
        "    return {\n",
        "        'id': nid,\n",
        "        'type': 'LoRA',\n",
        "        'args': {'path': lora_path, 'weight': weight}\n",
        "    }\n",
        "\n",
        "\n",
        "def make_upscaler_node(scale=2):\n",
        "    nid = _next_node_id()\n",
        "    return {\n",
        "        'id': nid,\n",
        "        'type': 'Upscaler',\n",
        "        'args': {'scale': scale}\n",
        "    }\n",
        "\n",
        "# --- ComfyUI-style node builders\n",
        "\n",
        "def _node_id_str():\n",
        "    return str(_next_node_id())\n",
        "\n",
        "\n",
        "def comfy_checkpoint_loader(model_key=None):\n",
        "    nid = _node_id_str()\n",
        "    # CheckpointLoaderSimple usually references a model name or path; adapt as needed\n",
        "    return nid, {\n",
        "        'id': nid,\n",
        "        'type': 'CheckpointLoaderSimple',\n",
        "        'name': 'CheckpointLoaderSimple',\n",
        "        'args': {'ckpt_name': model_key or ''},\n",
        "        'inputs': {}\n",
        "    }\n",
        "\n",
        "\n",
        "def comfy_clip_text_encode(prompt):\n",
        "    nid = _node_id_str()\n",
        "    return nid, {\n",
        "        'id': nid,\n",
        "        'type': 'CLIPTextEncode',\n",
        "        'name': 'CLIPTextEncode',\n",
        "        'args': {'text': prompt},\n",
        "        'inputs': {}\n",
        "    }\n",
        "\n",
        "\n",
        "def comfy_ksampler(sampler='DDIM', steps=20, seed=-1):\n",
        "    nid = _node_id_str()\n",
        "    return nid, {\n",
        "        'id': nid,\n",
        "        'type': 'KSampler',\n",
        "        'name': 'KSampler',\n",
        "        'args': {'sampler_name': sampler, 'steps': steps, 'seed': seed},\n",
        "        'inputs': {}\n",
        "    }\n",
        "\n",
        "\n",
        "def comfy_lora_loader(lora_path, weight=0.8):\n",
        "    nid = _node_id_str()\n",
        "    return nid, {\n",
        "        'id': nid,\n",
        "        'type': 'LoraLoader',\n",
        "        'name': 'LoraLoader',\n",
        "        'args': {'path': lora_path, 'weight': weight},\n",
        "        'inputs': {}\n",
        "    }\n",
        "\n",
        "\n",
        "def comfy_latent_upscaler(scale=2):\n",
        "    nid = _node_id_str()\n",
        "    return nid, {\n",
        "        'id': nid,\n",
        "        'type': 'LatentUpscaler',\n",
        "        'name': 'LatentUpscaler',\n",
        "        'args': {'scale': scale},\n",
        "        'inputs': {}\n",
        "    }\n",
        "\n",
        "\n",
        "def comfy_save_image(filename=None):\n",
        "    nid = _node_id_str()\n",
        "    return nid, {\n",
        "        'id': nid,\n",
        "        'type': 'SaveImage',\n",
        "        'name': 'SaveImage',\n",
        "        'args': {'path': filename or ''},\n",
        "        'inputs': {}\n",
        "    }\n",
        "\n",
        "# Compose flow with two modes\n",
        "\n",
        "def compose_flow(prompt, model_key=None, sampler='DDIM', steps=20, seed=-1, lora=None, upscaler=None, format='comfyui'):\n",
        "    \"\"\"Compose a flow and write it to disk. Returns (path, flow_dict).\n",
        "\n",
        "    format: 'simple' or 'comfyui'\n",
        "    \"\"\"\n",
        "    if format not in ('simple', 'comfyui'):\n",
        "        raise ValueError('Unsupported format')\n",
        "\n",
        "    if format == 'simple':\n",
        "        nodes = []\n",
        "        enc = make_text_encoder_node(prompt)\n",
        "        nodes.append(enc)\n",
        "        samp = make_sampler_node(sampler=sampler, steps=steps, seed=seed)\n",
        "        nodes.append(samp)\n",
        "        if lora:\n",
        "            nodes.append(make_lora_node(lora))\n",
        "        if upscaler:\n",
        "            nodes.append(make_upscaler_node(upscaler))\n",
        "        flow = {'metadata': {'created': int(time.time()), 'prompt': prompt, 'model_key': model_key}, 'nodes': nodes}\n",
        "    else:\n",
        "        nodes = {}\n",
        "        # Create core nodes: checkpoint loader, clip encode, sampler, optionally lora, upscaler, saver\n",
        "        ck_id, ck_node = comfy_checkpoint_loader(model_key)\n",
        "        nodes[ck_id] = ck_node\n",
        "        txt_id, txt_node = comfy_clip_text_encode(prompt)\n",
        "        nodes[txt_id] = txt_node\n",
        "        samp_id, samp_node = comfy_ksampler(sampler=sampler, steps=steps, seed=seed)\n",
        "        nodes[samp_id] = samp_node\n",
        "        # Hook up a basic conceptual wiring via 'inputs' (note: this is a minimal representation;\n",
        "        # full ComfyUI flows may use connection maps — here we provide args and a simple structure\n",
        "        # that many importers can accept or that can be further edited in the ComfyUI graph UI).\n",
        "        if lora:\n",
        "            l_id, l_node = comfy_lora_loader(lora)\n",
        "            nodes[l_id] = l_node\n",
        "        if upscaler:\n",
        "            u_id, u_node = comfy_latent_upscaler(upscaler)\n",
        "            nodes[u_id] = u_node\n",
        "        save_name = f'generated_{int(time.time())}.png'\n",
        "        s_id, s_node = comfy_save_image(save_name)\n",
        "        nodes[s_id] = s_node\n",
        "\n",
        "        flow = {'metadata': {'created': int(time.time()), 'prompt': prompt, 'model_key': model_key, 'comfyui_format': True}, 'nodes': nodes}\n",
        "\n",
        "    fname = FLOWS_DIR / f'flow_generated_{int(time.time())}.json'\n",
        "    with open(fname, 'w', encoding='utf-8') as fh:\n",
        "        json.dump(flow, fh, indent=2)\n",
        "    return str(fname), flow\n",
        "\n",
        "print('Complex node helpers loaded. Use compose_flow(prompt, model_key, ..., format=\"comfyui\") to create a ComfyUI-compatible flow JSON.')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "YT0oOOLefbmL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "_hUI78WQbzJl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Extract workflows from showcase images (attempt)\n",
        "# This cell tries to download showcased images from Civitai model pages and\n",
        "# inspect their PNG tEXt chunks and surrounding HTML for embedded ComfyUI workflows.\n",
        "# It saves any JSON it finds to DRIVE_ROOT/flows/extracted_{model_id}_{i}.json\n",
        "\n",
        "import os, re, requests\n",
        "from pathlib import Path\n",
        "from bs4 import BeautifulSoup\n",
        "from PIL import Image\n",
        "import base64, io, json\n",
        "\n",
        "DRIVE_ROOT = globals().get('DRIVE_ROOT', '/content/drive/MyDrive/ComfyUI')\n",
        "OUT_DIR = Path(DRIVE_ROOT)/'flows'/'extracted_images'\n",
        "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "model_pages = [\n",
        "  'https://civitai.com/models/1064836?modelVersionId=993999',\n",
        "  'https://civitai.com/models/652699?modelVersionId=993999'\n",
        "]\n",
        "\n",
        "session = requests.Session()\n",
        "# If CIVITAI_API_TOKEN is present, include it as a query token when downloading files, but for page scraping a logged-in session may be required\n",
        "CIVITAI_TOKEN = os.environ.get('CIVITAI_API_TOKEN','')\n",
        "headers = {'User-Agent':'ComfyUI-Playground/1.0'}\n",
        "\n",
        "extracted = []\n",
        "\n",
        "for url in model_pages:\n",
        "  print('\\nProcessing', url)\n",
        "  try:\n",
        "    r = session.get(url, headers=headers, timeout=15)\n",
        "    if r.status_code != 200:\n",
        "      print('Failed to fetch page (status', r.status_code, ') — content may be gated; skipping')\n",
        "      continue\n",
        "  except Exception as e:\n",
        "    print('Request failed:', e)\n",
        "    continue\n",
        "\n",
        "  soup = BeautifulSoup(r.text, 'html.parser')\n",
        "  imgs = soup.find_all('img')\n",
        "  print('Found', len(imgs), 'images on page (will attempt to inspect common showcase images)')\n",
        "  count = 0\n",
        "  for img in imgs:\n",
        "    src = img.get('data-src') or img.get('src') or ''\n",
        "    if not src:\n",
        "      continue\n",
        "    # skip tiny icons and badges\n",
        "    if any(x in src for x in ['/avatar', '/badge', 'base-badge', 'width=32']):\n",
        "      continue\n",
        "    # normalize URL\n",
        "    if src.startswith('//'):\n",
        "      src = 'https:' + src\n",
        "    if src.startswith('/'):\n",
        "      src = 'https://civitai.com' + src\n",
        "\n",
        "    # Download image\n",
        "    try:\n",
        "      print('Downloading', src)\n",
        "      ir = session.get(src, headers=headers, timeout=20)\n",
        "      if ir.status_code != 200:\n",
        "        print('Failed to download image', ir.status_code)\n",
        "        continue\n",
        "    except Exception as e:\n",
        "      print('Image download failed:', e)\n",
        "      continue\n",
        "\n",
        "    # Save image temporarily\n",
        "    count += 1\n",
        "    fn = OUT_DIR/f\"img_{Path(src).stem}_{count}.png\"\n",
        "    try:\n",
        "      fn.write_bytes(ir.content)\n",
        "    except Exception:\n",
        "      # try jpg\n",
        "      fn = fn.with_suffix('.jpg')\n",
        "      fn.write_bytes(ir.content)\n",
        "\n",
        "    # Attempt to read PNG tEXt chunks via PIL info\n",
        "    try:\n",
        "      im = Image.open(fn)\n",
        "      info = im.info\n",
        "      keys = list(info.keys())\n",
        "      if keys:\n",
        "        print('Image info keys:', keys)\n",
        "      else:\n",
        "        print('No textual PNG info keys found')\n",
        "\n",
        "      # Search textual info for JSON or base64-encoded workflows\n",
        "      for k,v in info.items():\n",
        "        s = str(v)\n",
        "        # heuristics: look for 'Comfy' or '{\"nodes' or long base64\n",
        "        if 'Comfy' in s or '{\"nodes' in s or re.search(r'^[A-Za-z0-9+/=\\n]{200,}$', s):\n",
        "          print('Candidate workflow text in PNG info key', k)\n",
        "          cand = s\n",
        "          # if base64, try decode\n",
        "          try:\n",
        "            if re.match(r'^[A-Za-z0-9+/=\\n]+$', cand.strip()):\n",
        "              dec = base64.b64decode(cand)\n",
        "              try:\n",
        "                j = json.loads(dec.decode('utf-8'))\n",
        "                outp = OUT_DIR/f'extracted_{Path(url).stem}_{count}.json'\n",
        "                outp.write_text(json.dumps(j, indent=2))\n",
        "                extracted.append(str(outp))\n",
        "                print('Extracted JSON saved to', outp)\n",
        "              except Exception:\n",
        "                # not JSON after decode\n",
        "                pass\n",
        "          except Exception:\n",
        "            pass\n",
        "\n",
        "    except Exception as e:\n",
        "      print('Failed to inspect image via PIL:', e)\n",
        "\n",
        "    # Fallback: search surrounding HTML for long base64 or JSON blobs\n",
        "    parent_html = str(img.parent)\n",
        "    m = re.search(r'([A-Za-z0-9+/=\\n]{200,})', parent_html)\n",
        "    if m:\n",
        "      cand = m.group(1)\n",
        "      try:\n",
        "        dec = base64.b64decode(cand)\n",
        "        j = json.loads(dec.decode('utf-8'))\n",
        "        outp = OUT_DIR/f'extracted_{Path(url).stem}_{count}_html.json'\n",
        "        outp.write_text(json.dumps(j, indent=2))\n",
        "        extracted.append(str(outp))\n",
        "        print('Extracted JSON from surrounding HTML to', outp)\n",
        "      except Exception:\n",
        "        pass\n",
        "\n",
        "  if count == 0:\n",
        "    print('No candidate showcase images downloaded for this page — it may be gated or use JS rendering.')\n",
        "\n",
        "print('\\nExtraction complete — found', len(extracted), 'candidate workflows (saved to DRIVE_ROOT/flows/extracted_images)')\n",
        "for p in extracted:\n",
        "  print('-', p)\n",
        "\n",
        "print('\\nReminder: NSFW or gated pages may require a logged-in session; set CIVITAI_API_TOKEN or download images manually then run the local extractor on those images.')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "uiD74GZedvk0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Collected and extracted workflows index\n",
        "# Lists any workflow JSONs extracted by the \"Extract workflows from showcase images\" cell\n",
        "from pathlib import Path\n",
        "DRIVE_ROOT = globals().get('DRIVE_ROOT','/content/drive/MyDrive/ComfyUI')\n",
        "EX_DIR = Path(DRIVE_ROOT)/'flows'/'extracted_images'\n",
        "EX_DIR.mkdir(parents=True, exist_ok=True)\n",
        "files = sorted([str(p) for p in EX_DIR.glob('*.json')])\n",
        "print('Found', len(files), 'extracted workflow JSON files in', EX_DIR)\n",
        "for f in files:\n",
        "    print('-', f)\n",
        "\n",
        "# If you have local images with embedded flows you want to inspect, upload them to Drive and re-run the extractor cell.\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "-QBp5yG1mlC4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Prompt-to-Image HTML UI + ComfyUI runner helper\n",
        "\"\"\"\n",
        "This UI now uses the composer to build a ComfyUI-style flow and returns the generated flow JSON\n",
        "so the front-end can preview it before the user decides to execute or save it.\n",
        "It accepts an optional `prompt_template` parameter (default='{prompt}') so callers can inject\n",
        "transcriptions or other text into a templated prompt (e.g. \"A photorealistic portrait of {prompt}\").\n",
        "\"\"\"\n",
        "from IPython.display import display, HTML\n",
        "from google.colab import output\n",
        "import json, os, time\n",
        "\n",
        "DRIVE_ROOT = globals().get('DRIVE_ROOT','/content/drive/MyDrive/ComfyUI')\n",
        "FLOWS_DIR = os.path.join(DRIVE_ROOT, 'flows')\n",
        "os.makedirs(FLOWS_DIR, exist_ok=True)\n",
        "\n",
        "# fetch available flow files\n",
        "flows = []\n",
        "for f in os.listdir(FLOWS_DIR):\n",
        "    if f.endswith('.json'):\n",
        "        flows.append(f)\n",
        "\n",
        "# basic HTML UI\n",
        "html = f'''\n",
        "<div style=\"font-family: Roboto, Arial; padding:8px; border:1px solid #ddd; border-radius:6px;\">\n",
        "  <h3>Prompt → Image</h3>\n",
        "  <div>\n",
        "    <label>Prompt</label><br>\n",
        "    <textarea id=\"p-prompt\" style=\"width:98%; height:80px\"></textarea>\n",
        "  </div>\n",
        "  <div style=\"margin-top:6px\">\n",
        "    <label>Model (manifest key)</label><br>\n",
        "    <input id=\"p-model\" style=\"width:200px\" placeholder=\"manifest key or model name\" />\n",
        "    <label style=\"margin-left:10px\">Workflow</label>\n",
        "    <select id=\"p-flow\">\n",
        "      <option value=\"\">-- choose saved flow --</option>\n",
        "      {''.join([f\"<option value='{f}'>{f}</option>\" for f in flows])}\n",
        "    </select>\n",
        "  </div>\n",
        "  <div style=\"margin-top:6px\">\n",
        "    <label>Sampler</label>\n",
        "    <input id=\"p-sampler\" value=\"DDIM\" style=\"width:120px\">\n",
        "    <label style=\"margin-left:8px\">Steps</label>\n",
        "    <input id=\"p-steps\" value=\"20\" style=\"width:80px\">\n",
        "    <label style=\"margin-left:8px\">Seed</label>\n",
        "    <input id=\"p-seed\" value=\"-1\" style=\"width:100px\">\n",
        "    <label style=\"margin-left:8px\"><input type=checkbox id='p-upscale' /> Upscale</label>\n",
        "  </div>\n",
        "  <div style=\"margin-top:6px\">\n",
        "    <label style=\"margin-right:8px\">Prompt template</label>\n",
        "    <input id=\"p-template\" value=\"{prompt}\" style=\"width:60%\" />\n",
        "  </div>\n",
        "  <div style=\"margin-top:8px\">\n",
        "    <button id=\"p-run\">Generate</button>\n",
        "    <button id=\"p-run-run\">Compose & Run (attempt API)</button>\n",
        "    <span id=\"p-status\" style=\"margin-left:12px; color:#333\"></span>\n",
        "  </div>\n",
        "  <div id=\"p-output\" style=\"margin-top:10px; white-space:pre-wrap; font-family:monospace; max-height:320px; overflow:auto\"></div>\n",
        "</div>\n",
        "<script>\n",
        "  async function showResult(resp){\n",
        "    const output = document.getElementById('p-output');\n",
        "    try{\n",
        "      const data = resp.data['application/json'];\n",
        "      output.innerText = JSON.stringify(data, null, 2);\n",
        "    }catch(e){\n",
        "      output.innerText = 'No response or failed to parse result.';\n",
        "    }\n",
        "  }\n",
        "\n",
        "  document.getElementById('p-run').onclick = async () => {\n",
        "    const prompt = document.getElementById('p-prompt').value;\n",
        "    const model = document.getElementById('p-model').value;\n",
        "    const flow = document.getElementById('p-flow').value;\n",
        "    const sampler = document.getElementById('p-sampler').value;\n",
        "    const steps = parseInt(document.getElementById('p-steps').value || '20');\n",
        "    const seed = parseInt(document.getElementById('p-seed').value || '-1');\n",
        "    const upscale = document.getElementById('p-upscale').checked;\n",
        "    const template = document.getElementById('p-template').value || '{prompt}';\n",
        "    document.getElementById('p-status').innerText = 'Composing flow...';\n",
        "    google.colab.kernel.invokeFunction('notebook.prompt_to_image', [prompt, model, flow, sampler, steps, seed, upscale, 'compose', template], {})\n",
        "      .then(showResult);\n",
        "  };\n",
        "\n",
        "  document.getElementById('p-run-run').onclick = async () => {\n",
        "    const prompt = document.getElementById('p-prompt').value;\n",
        "    const model = document.getElementById('p-model').value;\n",
        "    const flow = document.getElementById('p-flow').value;\n",
        "    const sampler = document.getElementById('p-sampler').value;\n",
        "    const steps = parseInt(document.getElementById('p-steps').value || '20');\n",
        "    const seed = parseInt(document.getElementById('p-seed').value || '-1');\n",
        "    const upscale = document.getElementById('p-upscale').checked;\n",
        "    const template = document.getElementById('p-template').value || '{prompt}';\n",
        "    document.getElementById('p-status').innerText = 'Composing and calling ComfyUI API...';\n",
        "    google.colab.kernel.invokeFunction('notebook.prompt_to_image', [prompt, model, flow, sampler, steps, seed, upscale, 'run', template], {})\n",
        "      .then(showResult);\n",
        "  };\n",
        "</script>\n",
        "'''\n",
        "\n",
        "\n",
        "display(HTML(html))\n",
        "\n",
        "# Python callback implementation\n",
        "\n",
        "try:\n",
        "    from . import compose_flow as _compose_flow  # try package style if notebook packaged\n",
        "    compose = _compose_flow\n",
        "except Exception:\n",
        "    compose = globals().get('compose_flow')\n",
        "\n",
        "if not compose:\n",
        "    print('Warning: compose_flow not available in this kernel namespace')\n",
        "\n",
        "# New: support prompt_template parameter\n",
        "\n",
        "def prompt_to_image(prompt, model_key, flow_file, sampler, steps, seed, upscale, action='compose', prompt_template='{prompt}'):\n",
        "    # Apply template\n",
        "    try:\n",
        "        final_prompt = prompt_template.format(prompt=prompt)\n",
        "    except Exception:\n",
        "        # fallback: simple replace\n",
        "        final_prompt = prompt_template.replace('{prompt}', prompt)\n",
        "\n",
        "    # compose a comfyui-style flow by default\n",
        "    path, flow = compose(final_prompt, model_key=model_key or None, sampler=sampler, steps=steps, seed=seed, lora=None, upscaler=(2 if upscale else None), format='comfyui')\n",
        "\n",
        "    if action == 'compose':\n",
        "        return {'flow_path': path, 'flow': flow}\n",
        "\n",
        "    # action == 'run' => attempt to call ComfyUI API\n",
        "    base = os.environ.get('COMFYUI_PUBLIC_URL') or os.environ.get('COMFYUI_API_BASE') or 'http://127.0.0.1:8188'\n",
        "    api_key = os.environ.get('COMFYUI_API_KEY')\n",
        "    headers = {'User-Agent':'ComfyUI-Playground/1.0', 'Content-Type':'application/json'}\n",
        "    if api_key:\n",
        "        headers['Authorization'] = f'Bearer {api_key}'\n",
        "\n",
        "    try:\n",
        "        import requests\n",
        "        url = base.rstrip('/') + '/run_flow'\n",
        "        r = requests.post(url, json=flow, headers=headers, timeout=120)\n",
        "        try:\n",
        "            j = r.json()\n",
        "        except Exception:\n",
        "            j = {'status_code': r.status_code, 'text': r.text}\n",
        "        return {'api_status': r.status_code, 'api_response': j, 'flow_path': path}\n",
        "    except Exception as e:\n",
        "        return {'error': str(e), 'flow_path': path}\n",
        "\n",
        "# register callback\n",
        "output.register_callback('notebook.prompt_to_image', prompt_to_image)\n",
        "print('Prompt-to-Image UI ready (callback: notebook.prompt_to_image).')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Q30omO9azgDk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "5E66cg0kpO1Z"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T2uVoaxMdw7o"
      },
      "source": [
        "## Custom Tools/FrameWork\n",
        "\n",
        "This section contains custom systems and functions. They are for creating small systems that can be used by other sections.\n",
        "\n",
        "Below are some Example systems:\n",
        "\n",
        "A simple download and gui system\n",
        "\n",
        "A simple manifest system that stores each model you download, scrapes info and meta-data from civitAI to populate the title, and other properties of the model. Scrapes sample images of the model and extracts the workflow to a folder on drive\n",
        "\n",
        "\n",
        "Each flow is saved into `DRIVE_ROOT/flows` (see the example save cell earlier). After you start ComfyUI, load these JSON files in the Flow Editor and wire any custom nodes present in your setup."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "LdqrXi0emgKZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Manifest resolver & validation\n",
        "\n",
        "This mini-section adds a safe resolver that—when you run it in Colab after mounting Drive and setting `CIVITAI_API_TOKEN`—will:\n",
        "\n",
        "- Read `DRIVE_ROOT/manifests/civitai_model_manifests.json`.\n",
        "- For each manifest entry, perform a HEAD or GET with `allow_redirects=True` to follow the Civitai redirect and inspect the `Content-Disposition` header (the API typically redirects to the actual file URL and provides a filename).\n",
        "- Save the resolved filename and a final download URL into the manifest file as `resolved_filename` and `resolved_url` for each model.\n",
        "\n",
        "Run the resolver only in a session where you have set `CIVITAI_API_TOKEN` using the secure token cell. The resolver will not download the whole files — it follows redirects and inspects headers only (uses `stream=True` and closes the connection quickly).\n",
        "\n",
        "Security note: do not paste your token into this notebook's plaintext cells; use the secure input cell instead."
      ],
      "metadata": {
        "id": "untp16dSnUKr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Per-model manifest parsing & download templates (guarded)\n",
        "\"\"\"\n",
        "Create a manifest of the provided Civitai model download URLs with probable file formats,\n",
        "recommended target directories, and guarded download commands that require\n",
        "CIVITAI_API_TOKEN to be set (use the secure token cell earlier).\n",
        "\n",
        "Run this cell after mounting Drive and setting CIVITAI_API_TOKEN (via the secure cell).\n",
        "\"\"\"\n",
        "import re, os, json\n",
        "from pathlib import Path\n",
        "\n",
        "DRIVE_ROOT = globals().get('DRIVE_ROOT','/content/drive/MyDrive/ComfyUI')\n",
        "MANIFEST_DIR = Path(DRIVE_ROOT)/'manifests'\n",
        "MANIFEST_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# List of URLs (de-duplicated)\n",
        "urls = [\n",
        "  'https://civitai.com/api/download/models/443821',\n",
        "  'https://civitai.com/api/download/models/1624818',\n",
        "  'https://civitai.com/api/download/models/1741501',\n",
        "  'https://civitai.com/api/download/models/2048863',\n",
        "  'https://civitai.com/api/download/models/2004155',\n",
        "  'https://civitai.com/api/download/models/2031069',\n",
        "  'https://civitai.com/api/download/models/1476909',\n",
        "  'https://civitai.com/api/download/models/1855263',\n",
        "  'https://civitai.com/api/download/models/1874153',\n",
        "  'https://civitai.com/api/download/models/1331682',\n",
        "  'https://civitai.com/api/download/models/15003',\n",
        "  'https://civitai.com/api/download/models/6424',\n",
        "  'https://civitai.com/api/download/models/1307155'\n",
        "]\n",
        "\n",
        "# Heuristics / prior knowledge mapping (from earlier notes and typical usage)\n",
        "# Use conservative guesses; if you know exact file names/formats update the manifest manually.\n",
        "format_suggestions = {\n",
        "  443821: {'formats':['SafeTensor'], 'target_dir':'{MODELS_DIR}/cyberrealistic'},\n",
        "  1624818: {'formats':['SafeTensor'], 'target_dir':'{LORAS_DIR}'},\n",
        "  1741501: {'formats':['SafeTensor'], 'target_dir':'{MODELS_DIR}/wan'},\n",
        "  2048863: {'formats':['GGUF','SafeTensor'], 'target_dir':'{GGUF_DIR}'},\n",
        "  2004155: {'formats':['SafeTensor','LoRA'], 'target_dir':'{LORAS_DIR}'},\n",
        "  2031069: {'formats':['GGUF','SafeTensor'], 'target_dir':'{GGUF_DIR}'},\n",
        "  1476909: {'formats':['SafeTensor'], 'target_dir':'{LORAS_DIR}'},\n",
        "  1855263: {'formats':['GGUF'], 'target_dir':'{GGUF_DIR}'},\n",
        "  1874153: {'formats':['GGUF'], 'target_dir':'{GGUF_DIR}'},\n",
        "  1331682: {'formats':['GGUF'], 'target_dir':'{GGUF_DIR}'},\n",
        "  15003: {'formats':['SafeTensor'], 'target_dir':'{MODELS_DIR}/cyberrealistic'},\n",
        "  6424: {'formats':['SafeTensor'], 'target_dir':'{MODELS_DIR}/chilloutmix'},\n",
        "  1307155: {'formats':['GGUF','SafeTensor'], 'target_dir':'{GGUF_DIR}'},\n",
        "}\n",
        "\n",
        "manifest = {}\n",
        "for u in urls:\n",
        "  m = re.search(r'/models/(\\d+)', u)\n",
        "  if not m:\n",
        "    continue\n",
        "  mid = int(m.group(1))\n",
        "  entry = {}\n",
        "  entry['model_id'] = mid\n",
        "  entry['download_url'] = u + '?CIVITAI_TOKEN=$CIVITAI_API_TOKEN'\n",
        "  sugg = format_suggestions.get(mid, None)\n",
        "  if sugg:\n",
        "    entry['suggested_formats'] = sugg['formats']\n",
        "    entry['recommended_dir_template'] = sugg['target_dir']\n",
        "  else:\n",
        "    entry['suggested_formats'] = ['SafeTensor','GGUF','Checkpoint','LoRA']\n",
        "    entry['recommended_dir_template'] = '{MODELS_DIR}'\n",
        "  # guarded wget template (comment before running) — you must set CIVITAI_API_TOKEN first\n",
        "  entry['download_template'] = f\"# !wget \\\"{entry['download_url']}\\\" --content-disposition -P \\\"{entry['recommended_dir_template']}\\\"\"\n",
        "  entry['notes'] = 'Set CIVITAI_API_TOKEN via the secure input cell and review the model page for NSFW gating or special instructions. If API returns a redirect or login-required, download via browser and upload to Drive.'\n",
        "  manifest[str(mid)] = entry\n",
        "\n",
        "# Save manifest JSON to Drive\n",
        "outp = MANIFEST_DIR/'civitai_model_manifests.json'\n",
        "outp.write_text(json.dumps(manifest, indent=2))\n",
        "print('Wrote manifest for', len(manifest), 'models to', outp)\n",
        "\n",
        "# Print a concise table for quick review\n",
        "for k,v in manifest.items():\n",
        "  print(f\"- Model {k}: suggested formats={v['suggested_formats']}, dir={v['recommended_dir_template']}\")\n",
        "  print('  Download template (commented):')\n",
        "  print('  ', v['download_template'])\n",
        "\n",
        "print('\\nReminder: uncomment and run the download_template commands only after setting CIVITAI_API_TOKEN with the secure token cell and verifying you have permission to download these models.')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "X5TnFqx6m9aY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Manifest resolver (follow redirects, capture filenames) — run after setting CIVITAI_API_TOKEN\n",
        "\"\"\"\n",
        "This cell reads the manifest saved at DRIVE_ROOT/manifests/civitai_model_manifests.json,\n",
        "performs a HEAD/GET to the API download URL (with CIVITAI token), follows redirects,\n",
        "and extracts the final filename from Content-Disposition if present.\n",
        "It updates the manifest with 'resolved_filename' and 'resolved_url' fields for each model.\n",
        "\n",
        "Note: run this only after mounting Drive and setting CIVITAI_API_TOKEN via the secure input cell.\n",
        "\"\"\"\n",
        "import os, requests, json\n",
        "from pathlib import Path\n",
        "\n",
        "DRIVE_ROOT = globals().get('DRIVE_ROOT','/content/drive/MyDrive/ComfyUI')\n",
        "MANIFEST_FILE = Path(DRIVE_ROOT)/'manifests'/'civitai_model_manifests.json'\n",
        "if not MANIFEST_FILE.exists():\n",
        "    print('Manifest file not found at', MANIFEST_FILE)\n",
        "else:\n",
        "    with open(MANIFEST_FILE,'r') as f:\n",
        "        manifest = json.load(f)\n",
        "\n",
        "    token = os.environ.get('CIVITAI_API_TOKEN','')\n",
        "    if not token:\n",
        "        print('CIVITAI_API_TOKEN not set. Use the secure input cell to set it for this session.')\n",
        "    else:\n",
        "        s = requests.Session()\n",
        "        s.headers.update({'User-Agent':'ComfyUI-Playground/1.0'})\n",
        "        updated = False\n",
        "        for mid, entry in manifest.items():\n",
        "            url = entry.get('download_url')\n",
        "            if not url:\n",
        "                print('No download_url for', mid)\n",
        "                continue\n",
        "            # substitute token placeholder if present\n",
        "            url = url.replace('$CIVITAI_API_TOKEN', token)\n",
        "            print('\\nResolving model', mid, '...')\n",
        "            try:\n",
        "                # Try HEAD first\n",
        "                r = s.head(url, allow_redirects=True, timeout=20)\n",
        "                if r.status_code >= 400:\n",
        "                    # try GET with stream to inspect headers\n",
        "                    r = s.get(url, stream=True, allow_redirects=True, timeout=20)\n",
        "                    r.close()\n",
        "                # final URL after redirects\n",
        "                final_url = r.url\n",
        "                cd = r.headers.get('Content-Disposition','')\n",
        "                filename = None\n",
        "                if cd:\n",
        "                    m = re.search(r'filename\\*=UTF-8''(.+)|filename=\"?([^\";]+)\"?', cd)\n",
        "                    if m:\n",
        "                        filename = m.group(1) or m.group(2)\n",
        "                # fallback: try last path segment\n",
        "                if not filename:\n",
        "                    filename = final_url.split('/')[-1].split('?')[0]\n",
        "                entry['resolved_url'] = final_url\n",
        "                entry['resolved_filename'] = filename\n",
        "                print('Resolved:', filename)\n",
        "                updated = True\n",
        "            except Exception as e:\n",
        "                print('Failed to resolve', mid, e)\n",
        "\n",
        "        if updated:\n",
        "            MANIFEST_FILE.write_text(json.dumps(manifest, indent=2))\n",
        "            print('\\nManifest updated with resolved filenames at', MANIFEST_FILE)\n",
        "        else:\n",
        "            print('\\nNo updates applied to manifest.')\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "lyYaLcVmnxSy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ARytyyT9n7Hh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "92a94b6d",
        "outputId": "5e53a8e8-5833-497d-b678-d2f807451f79",
        "cellView": "form"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Manifest not found at \\content\\drive\\MyDrive\\ComfyUI\\manifests\\civitai_model_manifests.json\n"
          ]
        }
      ],
      "source": [
        "#@title Batch manifest resolver — resolve final filenames and headers for manifest entries\n",
        "\"\"\"\n",
        "This cell iterates the manifest entries and attempts to resolve the final download URL, filename\n",
        "(Content-Disposition), content-length, and server-provided checksum (if present in headers or JSON) without\n",
        "downloading the full file. It will update the manifest with resolved_filename, resolved_url, content_length,\n",
        "and server_hash (if found). Run this in Colab after running the secure token input cell.\n",
        "\"\"\"\n",
        "import os, json, re, time\n",
        "from pathlib import Path\n",
        "import requests\n",
        "\n",
        "DRIVE_ROOT = globals().get('DRIVE_ROOT','/content/drive/MyDrive/ComfyUI')\n",
        "MANIFEST_PATH = Path(DRIVE_ROOT)/'manifests'/'civitai_model_manifests.json'\n",
        "\n",
        "if not MANIFEST_PATH.exists():\n",
        "    print('Manifest not found at', MANIFEST_PATH)\n",
        "else:\n",
        "    manifest = json.loads(MANIFEST_PATH.read_text())\n",
        "    token = os.environ.get('CIVITAI_API_TOKEN','')\n",
        "    if not token:\n",
        "        print('CIVITAI_API_TOKEN not set in environment. Run the secure token cell first.')\n",
        "    else:\n",
        "        s = requests.Session()\n",
        "        s.headers.update({'User-Agent':'ComfyUI-Playground/1.0'})\n",
        "        errors = []\n",
        "        for mid, entry in manifest.items():\n",
        "            url_tpl = entry.get('download_url','')\n",
        "            url = url_tpl.replace('$CIVITAI_API_TOKEN', token)\n",
        "            try:\n",
        "                r = s.head(url, allow_redirects=True, timeout=20)\n",
        "                # fallback to small GET if head fails\n",
        "                if r.status_code >= 400:\n",
        "                    r = s.get(url, stream=True, allow_redirects=True, timeout=20)\n",
        "                    r.close()\n",
        "                final_url = r.url\n",
        "                cd = r.headers.get('Content-Disposition','')\n",
        "                filename = None\n",
        "                if cd:\n",
        "                    m = re.search(r\"filename\\*=UTF-8''(.+)|filename=\\\"?([^\\\";]+)\\\"?\", cd)\n",
        "                    if m:\n",
        "                        filename = m.group(1) or m.group(2)\n",
        "                if not filename:\n",
        "                    filename = final_url.split('/')[-1].split('?')[0]\n",
        "                size = r.headers.get('Content-Length')\n",
        "                if size:\n",
        "                    size = int(size)\n",
        "                # server-provided checksum heuristics\n",
        "                server_hash = None\n",
        "                # Check common header fields\n",
        "                for h in ['ETag','Content-MD5','X-Checksum-Sha256','X-Checksum','x-amz-meta-sha256']:\n",
        "                    if r.headers.get(h):\n",
        "                        server_hash = r.headers.get(h)\n",
        "                        break\n",
        "                # If Content-Type is application/json and we did a small GET earlier, try to parse JSON\n",
        "                # to look for 'sha256' or similar in body\n",
        "                entry.update({\n",
        "                    'resolved_url': final_url,\n",
        "                    'resolved_filename': filename,\n",
        "                    'content_length': size,\n",
        "                    'server_hash': server_hash,\n",
        "                    'last_resolved': int(time.time())\n",
        "                })\n",
        "                manifest[mid] = entry\n",
        "                print(f\"Resolved {mid} -> {filename} ({size} bytes)\")\n",
        "            except Exception as e:\n",
        "                errors.append((mid,str(e)))\n",
        "                print(f\"Failed to resolve {mid}: {e}\")\n",
        "        MANIFEST_PATH.write_text(json.dumps(manifest, indent=2))\n",
        "        print('Resolver complete. Wrote manifest. Errors:', len(errors))\n",
        "        if errors:\n",
        "            for mid,err in errors:\n",
        "                print(mid, err)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Manifest post-processor: infer formats from resolved filenames\n",
        "\"\"\"\n",
        "Reads the manifest, and for entries with 'resolved_filename' attempts to infer format\n",
        "(safetensor, gguf, checkpoint, lora) based on extension and updates manifest['inferred_format'].\n",
        "\"\"\"\n",
        "import os, json\n",
        "from pathlib import Path\n",
        "\n",
        "DRIVE_ROOT = globals().get('DRIVE_ROOT','/content/drive/MyDrive/ComfyUI')\n",
        "MANIFEST_PATH = Path(DRIVE_ROOT)/'manifests'/'civitai_model_manifests.json'\n",
        "\n",
        "if not MANIFEST_PATH.exists():\n",
        "    print('Manifest not found at', MANIFEST_PATH)\n",
        "else:\n",
        "    m = json.loads(MANIFEST_PATH.read_text())\n",
        "    changed = False\n",
        "    for mid, entry in m.items():\n",
        "        fn = entry.get('resolved_filename') or entry.get('downloaded_path')\n",
        "        if not fn:\n",
        "            continue\n",
        "        fn_lower = fn.lower()\n",
        "        fmt = None\n",
        "        if fn_lower.endswith('.safetensors'):\n",
        "            fmt = 'SafeTensor'\n",
        "        elif fn_lower.endswith('.gguf'):\n",
        "            fmt = 'GGUF'\n",
        "        elif fn_lower.endswith('.pth') or fn_lower.endswith('.pt') or fn_lower.endswith('.ckpt'):\n",
        "            fmt = 'Checkpoint'\n",
        "        elif fn_lower.endswith('.safetensors.pt'):\n",
        "            fmt = 'SafeTensor'\n",
        "        elif '.safetensors' in fn_lower:\n",
        "            fmt = 'SafeTensor'\n",
        "        elif fn_lower.endswith('.bin'):\n",
        "            # could be HF bin; leave generic\n",
        "            fmt = 'Binary'\n",
        "        elif fn_lower.endswith('.lora') or 'lora' in fn_lower:\n",
        "            fmt = 'LoRA'\n",
        "        if fmt and entry.get('inferred_format') != fmt:\n",
        "            entry['inferred_format'] = fmt\n",
        "            m[mid] = entry\n",
        "            changed = True\n",
        "            print('Inferred', fmt, 'for model', mid, '->', fn)\n",
        "    if changed:\n",
        "        MANIFEST_PATH.write_text(json.dumps(m, indent=2))\n",
        "        print('Manifest updated with inferred formats at', MANIFEST_PATH)\n",
        "    else:\n",
        "        print('No changes to manifest')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "rgmyFCVFoNy7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dfdfca8e",
        "outputId": "d827a8da-6c89-49d1-a033-cc46c2489abf",
        "cellView": "form"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DRIVE_ROOT = /content/drive/MyDrive/ComfyUI\n",
            "Drive root does not exist. Did you mount Drive? Run the Drive mount cell first.\n"
          ]
        }
      ],
      "source": [
        "#@title Manifest locator helper — find possible manifests under DRIVE_ROOT\n",
        "\"\"\"\n",
        "If the Batch manifest resolver failed because the manifest file cannot be found,\n",
        "this helper scans the `DRIVE_ROOT` area for probable manifest JSONs and prints\n",
        "their paths. Run this after mounting Drive.\n",
        "\"\"\"\n",
        "from pathlib import Path\n",
        "import json, os\n",
        "\n",
        "DRIVE_ROOT = globals().get('DRIVE_ROOT','/content/drive/MyDrive/ComfyUI')\n",
        "print('DRIVE_ROOT =', DRIVE_ROOT)\n",
        "root = Path(DRIVE_ROOT)\n",
        "if not root.exists():\n",
        "    print('Drive root does not exist. Did you mount Drive? Run the Drive mount cell first.')\n",
        "else:\n",
        "    candidates = []\n",
        "    manifests_dir = root / 'manifests'\n",
        "    if manifests_dir.exists():\n",
        "        for p in manifests_dir.glob('*.json'):\n",
        "            candidates.append(p)\n",
        "    # wide search for likely filenames\n",
        "    if not candidates:\n",
        "        for p in root.rglob('*.json'):\n",
        "            name = p.name.lower()\n",
        "            if 'civitai' in name or 'manifest' in name or 'models' in name:\n",
        "                candidates.append(p)\n",
        "    # show top results\n",
        "    if not candidates:\n",
        "        print('No candidate manifest files found under', DRIVE_ROOT)\n",
        "    else:\n",
        "        print('Found candidate manifest files:')\n",
        "        for i,p in enumerate(sorted(set(candidates)), start=1):\n",
        "            print(f'{i}. {p} (size: {p.stat().st_size} bytes)')\n",
        "        print('\\nIf one of these is the manifest you want to use, you can:')\n",
        "        print(' - Copy it to', str(manifests_dir/'civitai_model_manifests.json'))\n",
        "        print(' - Or update the MANIFEST_PATH variable in the resolver/downloader cells to point to the file')\n",
        "        print('\\nExample:')\n",
        "        print(\"MANIFEST_PATH = Path('\" + str(sorted(set(candidates))[0]) + \"')\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Nightly manifest resolver (background scheduler)\n",
        "\"\"\"\n",
        "Starts a background scheduler that runs the Batch manifest resolver every `interval_seconds`.\n",
        "Note: Colab sessions often time out — only use this if your session stays alive.\n",
        "\"\"\"\n",
        "import threading, time, json\n",
        "from pathlib import Path\n",
        "from google.colab import output\n",
        "\n",
        "DRIVE_ROOT = globals().get('DRIVE_ROOT','/content/drive/MyDrive/ComfyUI')\n",
        "MANIFEST_PATH = Path(DRIVE_ROOT)/'manifests'/'civitai_model_manifests.json'\n",
        "\n",
        "scheduler_thread = None\n",
        "scheduler_stop_event = threading.Event()\n",
        "\n",
        "\n",
        "def run_resolver_once():\n",
        "    # import code from the resolver cell or re-implement minimal resolver here\n",
        "    import requests, re, time\n",
        "    if not MANIFEST_PATH.exists():\n",
        "        print('Manifest missing, cannot run resolver')\n",
        "        return\n",
        "    m = json.loads(MANIFEST_PATH.read_text())\n",
        "    token = os.environ.get('CIVITAI_API_TOKEN','')\n",
        "    if not token:\n",
        "        print('CIVITAI_API_TOKEN not set. Run secure token cell first.')\n",
        "        return\n",
        "    s = requests.Session()\n",
        "    s.headers.update({'User-Agent':'ComfyUI-Playground/1.0'})\n",
        "    for mid,entry in m.items():\n",
        "        try:\n",
        "            url = entry.get('download_url','').replace('$CIVITAI_API_TOKEN', token)\n",
        "            r = s.head(url, allow_redirects=True, timeout=20)\n",
        "            if r.status_code >= 400:\n",
        "                r = s.get(url, stream=True, allow_redirects=True, timeout=20)\n",
        "                r.close()\n",
        "            final_url = r.url\n",
        "            cd = r.headers.get('Content-Disposition','')\n",
        "            filename = None\n",
        "            if cd:\n",
        "                mm = re.search(r\"filename\\*=UTF-8''(.+)|filename=\\\"?([^\\\";]+)\\\"?\", cd)\n",
        "                if mm:\n",
        "                    filename = mm.group(1) or mm.group(2)\n",
        "            if not filename:\n",
        "                filename = final_url.split('/')[-1].split('?')[0]\n",
        "            size = r.headers.get('Content-Length')\n",
        "            if size:\n",
        "                size = int(size)\n",
        "            server_hash = None\n",
        "            for h in ['ETag','Content-MD5','X-Checksum-Sha256','X-Checksum','x-amz-meta-sha256']:\n",
        "                if r.headers.get(h):\n",
        "                    server_hash = r.headers.get(h)\n",
        "                    break\n",
        "            entry.update({'resolved_url':final_url,'resolved_filename':filename,'content_length':size,'server_hash':server_hash,'last_resolved':int(time.time())})\n",
        "            m[mid] = entry\n",
        "        except Exception as e:\n",
        "            print('Resolver failed for', mid, e)\n",
        "    MANIFEST_PATH.write_text(json.dumps(m, indent=2))\n",
        "    print('Resolver pass complete')\n",
        "\n",
        "\n",
        "def scheduler_start(interval_seconds=24*3600):\n",
        "    global scheduler_thread, scheduler_stop_event\n",
        "    if scheduler_thread and scheduler_thread.is_alive():\n",
        "        print('Scheduler already running')\n",
        "        return\n",
        "    scheduler_stop_event = threading.Event()\n",
        "    def loop():\n",
        "        while not scheduler_stop_event.is_set():\n",
        "            run_resolver_once()\n",
        "            # sleep with small increments to allow stop signal to be responsive\n",
        "            remaining = interval_seconds\n",
        "            while remaining > 0 and not scheduler_stop_event.is_set():\n",
        "                t = min(10, remaining)\n",
        "                time.sleep(t)\n",
        "                remaining -= t\n",
        "    scheduler_thread = threading.Thread(target=loop, daemon=True)\n",
        "    scheduler_thread.start()\n",
        "    print('Scheduler started with interval', interval_seconds)\n",
        "\n",
        "\n",
        "def scheduler_stop():\n",
        "    global scheduler_stop_event\n",
        "    if scheduler_stop_event:\n",
        "        scheduler_stop_event.set()\n",
        "        print('Scheduler stop requested')\n",
        "    else:\n",
        "        print('Scheduler not running')\n",
        "\n",
        "# register callbacks so user can start/stop from UI if desired\n",
        "output.register_callback('notebook.start_scheduler', lambda interval: scheduler_start(interval))\n",
        "output.register_callback('notebook.stop_scheduler', lambda : scheduler_stop())\n",
        "print('Scheduler helpers registered (start_scheduler, stop_scheduler)')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "y9MZIjmAyl3b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "ogptj4N6miiO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SQLite Helpers\n",
        "\n",
        "Simple SQLite storage and retrieval\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "GqSIJX3Lrcub"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "_ghbiQ7UsJd-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title SQLite-backed queue store & per-item cancel API\n",
        "\"\"\"\n",
        "Implements a small SQLite-backed queue to persist items and allow per-item cancellations.\n",
        "This cell exposes simple helpers to enqueue items, cancel them by id, and query the queue.\n",
        "It integrates with the advanced worker by reading the SQLite queue if present.\n",
        "\"\"\"\n",
        "import sqlite3\n",
        "from pathlib import Path\n",
        "import json, time\n",
        "\n",
        "DRIVE_ROOT = globals().get('DRIVE_ROOT','/content/drive/MyDrive/ComfyUI')\n",
        "DB_PATH = Path(DRIVE_ROOT)/'comfyui_queue.db'\n",
        "DB_PATH.parent.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "conn = sqlite3.connect(str(DB_PATH), check_same_thread=False)\n",
        "conn.execute('''CREATE TABLE IF NOT EXISTS queue (\n",
        "    id TEXT PRIMARY KEY,\n",
        "    manifest_key TEXT,\n",
        "    status TEXT,\n",
        "    attempts INTEGER DEFAULT 0,\n",
        "    last_error TEXT,\n",
        "    created_at REAL,\n",
        "    updated_at REAL\n",
        ")''')\n",
        "conn.commit()\n",
        "\n",
        "\n",
        "def enqueue_item(manifest_key):\n",
        "    mid = str(int(time.time()*1000))\n",
        "    now = time.time()\n",
        "    conn.execute('INSERT OR REPLACE INTO queue (id,manifest_key,status,attempts,created_at,updated_at) VALUES (?,?,?,?,?,?)', (mid, str(manifest_key), 'queued', 0, now, now))\n",
        "    conn.commit()\n",
        "    return mid\n",
        "\n",
        "\n",
        "def cancel_item(id):\n",
        "    conn.execute('UPDATE queue SET status=?, updated_at=? WHERE id=?', ('cancelled', time.time(), id))\n",
        "    conn.commit()\n",
        "\n",
        "\n",
        "def get_queue_items(limit=100):\n",
        "    cur = conn.execute('SELECT id, manifest_key, status, attempts, last_error, created_at, updated_at FROM queue ORDER BY created_at LIMIT ?', (limit,))\n",
        "    rows = cur.fetchall()\n",
        "    items = []\n",
        "    for r in rows:\n",
        "        items.append({'id':r[0],'manifest_key':r[1],'status':r[2],'attempts':r[3],'last_error':r[4],'created_at':r[5],'updated_at':r[6]})\n",
        "    return items\n",
        "\n",
        "print('SQLite queue helper loaded. DB at', DB_PATH)\n",
        "print('Useful functions: enqueue_item(manifest_key), cancel_item(id), get_queue_items()')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "rwlPB8I3sRy5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Register per-item cancel callback (links dashboard -> SQLite cancel)\n",
        "\"\"\"\n",
        "Registers a kernel callback 'notebook.cancel_item' which cancels a given queue item id\n",
        "in the SQLite queue and updates the JSON queue state file.\n",
        "\"\"\"\n",
        "from google.colab import output\n",
        "from pathlib import Path\n",
        "import json, time\n",
        "\n",
        "DRIVE_ROOT = globals().get('DRIVE_ROOT','/content/drive/MyDrive/ComfyUI')\n",
        "QUEUE_STATE_PATH = Path(DRIVE_ROOT)/'.queue_state.json'\n",
        "DB_PATH = Path(DRIVE_ROOT)/'comfyui_queue.db'\n",
        "\n",
        "# import cancel_item from the sqlite helper cell's namespace if available; otherwise define a fallback\n",
        "try:\n",
        "    cancel_item\n",
        "except NameError:\n",
        "    def cancel_item(id):\n",
        "        # fallback: mark in queue_state\n",
        "        if QUEUE_STATE_PATH.exists():\n",
        "            st = json.loads(QUEUE_STATE_PATH.read_text())\n",
        "        else:\n",
        "            st = {'items':{}}\n",
        "        st.setdefault('items',{})\n",
        "        st['items'].setdefault(str(id),{})\n",
        "        st['items'][str(id)]['status'] = 'cancelled'\n",
        "        st['items'][str(id)]['updated_at'] = int(time.time())\n",
        "        QUEUE_STATE_PATH.write_text(json.dumps(st, indent=2))\n",
        "        print('Fallback: cancelled', id)\n",
        "\n",
        "\n",
        "def cancel_item_callback(item_id):\n",
        "    try:\n",
        "        cancel_item(item_id)\n",
        "        # also update JSON state if present\n",
        "        if QUEUE_STATE_PATH.exists():\n",
        "            st = json.loads(QUEUE_STATE_PATH.read_text())\n",
        "            st.setdefault('items',{})\n",
        "            st['items'].setdefault(str(item_id),{})\n",
        "            st['items'][str(item_id)]['status'] = 'cancelled'\n",
        "            st['items'][str(item_id)]['updated_at'] = int(time.time())\n",
        "            QUEUE_STATE_PATH.write_text(json.dumps(st, indent=2))\n",
        "        print('Cancelled item', item_id)\n",
        "    except Exception as e:\n",
        "        print('Failed to cancel item', item_id, e)\n",
        "\n",
        "output.register_callback('notebook.cancel_item', cancel_item_callback)\n",
        "print('Registered kernel callback: notebook.cancel_item')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "MUUJGanJsK0S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "KjIBjN8FsGBR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "QUEUE WORKERS (XXXXXXXXXXXXXXXXXXXX)"
      ],
      "metadata": {
        "id": "alAp6BX_tQNt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "vp4_JEu2tsz9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Advanced persistent queue worker (resume, backoff retries, progress persistence)\n",
        "\"\"\"\n",
        "This worker improves upon the earlier implementation by:\n",
        "- Persisting queue state to DRIVE_ROOT/.queue_state.json so the queue can be resumed after kernel reconnects\n",
        "- Per-item progress tracking (bytes downloaded and percent when content-length present)\n",
        "- Exponential backoff retry strategy configurable per-call\n",
        "- get_queue_status callback to return the current queue state for the UI to poll\n",
        "\n",
        "Usage: use the rich HTML dashboard below which polls `notebook.get_queue_status` and calls\n",
        "`notebook.start_queue` and `notebook.stop_queue` to control the worker.\n",
        "\"\"\"\n",
        "import threading, time, json, os, traceback\n",
        "from pathlib import Path\n",
        "import requests\n",
        "import hashlib\n",
        "from google.colab import output\n",
        "\n",
        "DRIVE_ROOT = globals().get('DRIVE_ROOT','/content/drive/MyDrive/ComfyUI')\n",
        "MANIFEST_PATH = Path(DRIVE_ROOT)/'manifests'/'civitai_model_manifests.json'\n",
        "QUEUE_STATE_PATH = Path(DRIVE_ROOT)/'.queue_state.json'\n",
        "\n",
        "worker_thread = None\n",
        "worker_stop_event = threading.Event()\n",
        "worker_lock = threading.Lock()\n",
        "\n",
        "# Helper: read/write queue state\n",
        "\n",
        "def load_queue_state():\n",
        "    if QUEUE_STATE_PATH.exists():\n",
        "        try:\n",
        "            return json.loads(QUEUE_STATE_PATH.read_text())\n",
        "        except Exception:\n",
        "            return {'items':{}}\n",
        "    return {'items':{}}\n",
        "\n",
        "def write_queue_state(state):\n",
        "    QUEUE_STATE_PATH.parent.mkdir(parents=True, exist_ok=True)\n",
        "    QUEUE_STATE_PATH.write_text(json.dumps(state, indent=2))\n",
        "\n",
        "# initialize state if missing\n",
        "if not QUEUE_STATE_PATH.exists():\n",
        "    write_queue_state({'items':{}})\n",
        "\n",
        "# improved header normalization\n",
        "\n",
        "def normalize_header_hash(hdr):\n",
        "    if not hdr:\n",
        "        return None\n",
        "    h = str(hdr).strip().strip('\"')\n",
        "    if '-' in h:\n",
        "        return {'value':h,'type':'etag-multipart'}\n",
        "    if len(h) == 32 and all(c in '0123456789abcdefABCDEF' for c in h):\n",
        "        return {'value':h.lower(),'type':'md5'}\n",
        "    if len(h) == 64 and all(c in '0123456789abcdefABCDEF' for c in h):\n",
        "        return {'value':h.lower(),'type':'sha256'}\n",
        "    # provider-specific heuristics (very basic): strip surrounding 'W/' or other prefixes\n",
        "    h2 = h.replace('W/','').strip()\n",
        "    if len(h2) in (32,64) and all(c in '0123456789abcdefABCDEF' for c in h2):\n",
        "        t = 'md5' if len(h2)==32 else 'sha256'\n",
        "        return {'value':h2.lower(),'type':t}\n",
        "    return {'value':h,'type':'unknown'}\n",
        "\n",
        "# download with progress and state updates\n",
        "\n",
        "def compute_sha256(path):\n",
        "    h = hashlib.sha256()\n",
        "    with open(path, 'rb') as fh:\n",
        "        for chunk in iter(lambda: fh.read(1024*1024), b''):\n",
        "            h.update(chunk)\n",
        "    return h.hexdigest()\n",
        "\n",
        "\n",
        "def update_item_state(mid, **kwargs):\n",
        "    state = load_queue_state()\n",
        "    items = state.setdefault('items',{})\n",
        "    item = items.setdefault(str(mid), {})\n",
        "    item.update(kwargs)\n",
        "    write_queue_state(state)\n",
        "\n",
        "\n",
        "def download_item_with_progress(mid, entry, retry_count=2, stop_event=None):\n",
        "    token = os.environ.get('CIVITAI_API_TOKEN','')\n",
        "    s = requests.Session()\n",
        "    s.headers.update({'User-Agent':'ComfyUI-Playground/1.0'})\n",
        "    url_tpl = entry.get('download_url','')\n",
        "    if not url_tpl:\n",
        "        update_item_state(mid, status='no_url')\n",
        "        return False\n",
        "    url = url_tpl.replace('$CIVITAI_API_TOKEN', token)\n",
        "    final_url = entry.get('resolved_url') or url\n",
        "    filename = entry.get('resolved_filename') or final_url.split('/')[-1].split('?')[0]\n",
        "    suggested_tpl = entry.get('recommended_dir_template','{MODELS_DIR}')\n",
        "    mapping = {\n",
        "        '{MODELS_DIR}': globals().get('MODELS_DIR', str(Path(DRIVE_ROOT)/'models')),\n",
        "        '{LORAS_DIR}': globals().get('LORAS_DIR', str(Path(DRIVE_ROOT)/'models'/'loras')),\n",
        "        '{GGUF_DIR}': globals().get('GGUF_DIR', str(Path(DRIVE_ROOT)/'models'/'gguf')),\n",
        "        '{ARTIFACTS_DIR}': globals().get('ARTIFACTS_DIR', str(Path(DRIVE_ROOT)/'artifacts')),\n",
        "    }\n",
        "    for k,v in mapping.items():\n",
        "        suggested_tpl = suggested_tpl.replace(k,v)\n",
        "    target_dir = Path(suggested_tpl)\n",
        "    target_dir.mkdir(parents=True, exist_ok=True)\n",
        "    target_path = target_dir/filename\n",
        "\n",
        "    attempts = 0\n",
        "    backoff_base = 2\n",
        "    while attempts <= retry_count:\n",
        "        if stop_event and stop_event.is_set():\n",
        "            update_item_state(mid, status='cancelled')\n",
        "            return False\n",
        "        try:\n",
        "            update_item_state(mid, status='starting', attempts=attempts+1, filename=str(target_path))\n",
        "            r = s.get(final_url, stream=True, timeout=60)\n",
        "            r.raise_for_status()\n",
        "            total = r.headers.get('Content-Length')\n",
        "            if total:\n",
        "                total = int(total)\n",
        "            tmp = str(target_path) + '.part'\n",
        "            downloaded = 0\n",
        "            with open(tmp, 'wb') as fh:\n",
        "                for chunk in r.iter_content(chunk_size=256*1024):\n",
        "                    if chunk:\n",
        "                        fh.write(chunk)\n",
        "                        downloaded += len(chunk)\n",
        "                        # update progress\n",
        "                        if total:\n",
        "                            pct = int(downloaded*100/total)\n",
        "                        else:\n",
        "                            pct = None\n",
        "                        update_item_state(mid, status='downloading', bytes=downloaded, bytes_total=total, percent=pct)\n",
        "                        if stop_event and stop_event.is_set():\n",
        "                            update_item_state(mid, status='cancelled')\n",
        "                            return False\n",
        "            Path(tmp).rename(target_path)\n",
        "            sha = compute_sha256(target_path)\n",
        "            entry['downloaded_path'] = str(target_path)\n",
        "            entry['sha256'] = sha\n",
        "            entry['file_size_bytes'] = target_path.stat().st_size\n",
        "            entry['download_status'] = 'ok'\n",
        "            # server hash check\n",
        "            hdr = entry.get('server_hash')\n",
        "            sh = normalize_header_hash(hdr)\n",
        "            if sh:\n",
        "                if sh['type'] == 'sha256':\n",
        "                    entry.setdefault('integrity',{})\n",
        "                    entry['integrity']['server_hash'] = sh['value']\n",
        "                    entry['integrity']['server_hash_match'] = (sha == sh['value'])\n",
        "                elif sh['type'] == 'md5':\n",
        "                    import hashlib as _hashlib\n",
        "                    m = _hashlib.md5()\n",
        "                    with open(target_path, 'rb') as fh:\n",
        "                        for chunk in iter(lambda: fh.read(1024*1024), b''):\n",
        "                            m.update(chunk)\n",
        "                    entry.setdefault('integrity',{})\n",
        "                    entry['integrity']['server_hash'] = sh['value']\n",
        "                    entry['integrity']['server_hash_match'] = (m.hexdigest() == sh['value'])\n",
        "                else:\n",
        "                    entry.setdefault('integrity',{})\n",
        "                    entry['integrity']['server_hash'] = sh['value']\n",
        "                    entry['integrity']['server_hash_match'] = 'unknown'\n",
        "            # persist manifest incrementally\n",
        "            if MANIFEST_PATH.exists():\n",
        "                try:\n",
        "                    with open(MANIFEST_PATH, 'r', encoding='utf-8') as fh:\n",
        "                        m = json.load(fh)\n",
        "                except Exception:\n",
        "                    m = {}\n",
        "            else:\n",
        "                m = {}\n",
        "            m[str(mid)] = entry\n",
        "            with open(MANIFEST_PATH, 'w', encoding='utf-8') as fh:\n",
        "                json.dump(m, fh, indent=2)\n",
        "            update_item_state(mid, status='ok', sha256=sha, file_size=entry['file_size_bytes'])\n",
        "            return True\n",
        "        except Exception as e:\n",
        "            attempts += 1\n",
        "            last_err = str(e)\n",
        "            update_item_state(mid, status='error', last_error=last_err, attempts=attempts)\n",
        "            if attempts > retry_count:\n",
        "                update_item_state(mid, status='failed', last_error=last_err)\n",
        "                # persist failed state in manifest\n",
        "                if MANIFEST_PATH.exists():\n",
        "                    try:\n",
        "                        with open(MANIFEST_PATH, 'r', encoding='utf-8') as fh:\n",
        "                            m = json.load(fh)\n",
        "                    except Exception:\n",
        "                        m = {}\n",
        "                    ent = m.get(str(mid), {})\n",
        "                    ent['download_status'] = 'failed'\n",
        "                    ent.setdefault('integrity',{})\n",
        "                    ent['integrity']['last_error'] = last_err\n",
        "                    m[str(mid)] = ent\n",
        "                    with open(MANIFEST_PATH, 'w', encoding='utf-8') as fh:\n",
        "                        json.dump(m, fh, indent=2)\n",
        "                return False\n",
        "            # exponential backoff\n",
        "            sleep_for = backoff_base ** attempts\n",
        "            update_item_state(mid, status='retrying', next_wait=sleep_for)\n",
        "            time.sleep(sleep_for)\n",
        "    return False\n",
        "\n",
        "# worker loop that persists state\n",
        "\n",
        "def worker_main(ids, retry_count=2, stop_event=None):\n",
        "    print('Worker started for ids:', ids)\n",
        "    state = load_queue_state()\n",
        "    for mid in ids:\n",
        "        if stop_event and stop_event.is_set():\n",
        "            print('Stop requested — exiting worker')\n",
        "            break\n",
        "        # initialize state entry\n",
        "        update_item_state(mid, status='queued', attempts=0)\n",
        "    for mid in ids:\n",
        "        # load latest manifest entry\n",
        "        try:\n",
        "            if MANIFEST_PATH.exists():\n",
        "                with open(MANIFEST_PATH, 'r', encoding='utf-8') as fh:\n",
        "                    manifest = json.load(fh)\n",
        "            else:\n",
        "                manifest = {}\n",
        "            entry = manifest.get(str(mid), {})\n",
        "            download_item_with_progress(mid, entry, retry_count=retry_count, stop_event=stop_event)\n",
        "        except Exception as e:\n",
        "            print('Worker error for', mid, e)\n",
        "            traceback.print_exc()\n",
        "    print('Worker finished')\n",
        "\n",
        "# control functions\n",
        "\n",
        "def start_queue_callback(ids, enable_retries=False, retry_count=2):\n",
        "    global worker_thread, worker_stop_event\n",
        "    with worker_lock:\n",
        "        if worker_thread and worker_thread.is_alive():\n",
        "            print('A worker is already running')\n",
        "            return\n",
        "        worker_stop_event = threading.Event()\n",
        "        # ensure ids is a simple list of strings\n",
        "        ids = [str(x) for x in ids]\n",
        "        # persist initial queue state and items order\n",
        "        st = load_queue_state()\n",
        "        st['order'] = ids\n",
        "        for i in ids:\n",
        "            st.setdefault('items',{})\n",
        "            st['items'].setdefault(str(i), {'status':'queued'})\n",
        "        write_queue_state(st)\n",
        "        worker_thread = threading.Thread(target=worker_main, args=(ids, retry_count, worker_stop_event), daemon=True)\n",
        "        worker_thread.start()\n",
        "        print('Started worker thread with ids:', ids)\n",
        "\n",
        "\n",
        "def stop_queue_callback():\n",
        "    global worker_thread, worker_stop_event\n",
        "    with worker_lock:\n",
        "        if worker_thread and worker_thread.is_alive():\n",
        "            worker_stop_event.set()\n",
        "            worker_thread.join(timeout=5)\n",
        "            print('Worker stopped')\n",
        "        else:\n",
        "            print('No active worker')\n",
        "\n",
        "\n",
        "def get_queue_status_callback():\n",
        "    st = load_queue_state()\n",
        "    return st\n",
        "\n",
        "# register callbacks\n",
        "output.register_callback('notebook.start_queue', start_queue_callback)\n",
        "output.register_callback('notebook.stop_queue', stop_queue_callback)\n",
        "output.register_callback('notebook.get_queue_status', get_queue_status_callback)\n",
        "print('Advanced persistent worker callbacks registered: start_queue, stop_queue, get_queue_status')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "RP6FpWzdtoG5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "MY_OUZbKtNhi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "UNIFIED DOWWNLOAD SYSTEM\n",
        "\n",
        "### Quick notes — interactive downloader\n",
        "\n",
        "- Use the secure CIVITAI token cell before attempting downloads.\n",
        "- Steps:\n",
        "  1. Run the manifest resolver cell to populate `resolved_filename` for each model (uses token).\n",
        "  2. Use the Interactive download runner to preview and confirm a single model download.\n",
        "  3. The runner streams the file into Drive and updates the manifest with `downloaded_path`.\n",
        "- If a model is gated beyond token access, download via browser and upload to Drive; then update the manifest manually."
      ],
      "metadata": {
        "id": "UBmXjaRpuEDV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Interactive download runner (single model) — guarded and resumable\n",
        "\"\"\"\n",
        "Two-step UI: pick a model from the manifest, preview the resolved filename and size,\n",
        "then confirm to stream-download the file into the suggested directory. Requires\n",
        "CIVITAI_API_TOKEN set by the secure input cell.\n",
        "\"\"\"\n",
        "import os, json, re, requests, math\n",
        "from pathlib import Path\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output\n",
        "\n",
        "DRIVE_ROOT = globals().get('DRIVE_ROOT','/content/drive/MyDrive/ComfyUI')\n",
        "MANIFEST_PATH = Path(DRIVE_ROOT)/'manifests'/'civitai_model_manifests.json'\n",
        "\n",
        "def load_manifest():\n",
        "    if not MANIFEST_PATH.exists():\n",
        "        return {}\n",
        "    return json.loads(MANIFEST_PATH.read_text())\n",
        "\n",
        "manifest = load_manifest()\n",
        "if not manifest:\n",
        "    print('No manifest found at', MANIFEST_PATH)\n",
        "else:\n",
        "    options = []\n",
        "    for k,v in sorted(manifest.items(), key=lambda x:int(x[0])):\n",
        "        label = f\"{k}: {v.get('suggested_formats')}\"\n",
        "        if v.get('resolved_filename'):\n",
        "            label += f\" -> {v.get('resolved_filename')}\"\n",
        "        options.append((label,k))\n",
        "\n",
        "    dropdown = widgets.Dropdown(options=options, description='Model:')\n",
        "    preview_btn = widgets.Button(description='Preview')\n",
        "    confirm_btn = widgets.Button(description='Confirm & Download', button_style='danger')\n",
        "    out = widgets.Output()\n",
        "\n",
        "    def expand_dir_template(tpl):\n",
        "        # replace placeholders with notebook globals\n",
        "        mapping = {\n",
        "            '{MODELS_DIR}': globals().get('MODELS_DIR', str(Path(DRIVE_ROOT)/'models')),\n",
        "            '{LORAS_DIR}': globals().get('LORAS_DIR', str(Path(DRIVE_ROOT)/'models'/'loras')),\n",
        "            '{GGUF_DIR}': globals().get('GGUF_DIR', str(Path(DRIVE_ROOT)/'models'/'gguf')),\n",
        "            '{ARTIFACTS_DIR}': globals().get('ARTIFACTS_DIR', str(Path(DRIVE_ROOT)/'artifacts')),\n",
        "        }\n",
        "        for k,v in mapping.items():\n",
        "            tpl = tpl.replace(k, v)\n",
        "        return tpl\n",
        "\n",
        "    current_preview = {'mid':None, 'entry':None, 'final_url':None, 'filename':None, 'size':None}\n",
        "\n",
        "    def on_preview(b):\n",
        "        with out:\n",
        "            clear_output()\n",
        "            mid = dropdown.value\n",
        "            entry = manifest.get(str(mid))\n",
        "            if not entry:\n",
        "                print('Manifest entry not found for', mid)\n",
        "                return\n",
        "            token = os.environ.get('CIVITAI_API_TOKEN','')\n",
        "            if not token:\n",
        "                print('CIVITAI_API_TOKEN not set. Run the secure token cell first.')\n",
        "                return\n",
        "            url = entry.get('download_url','').replace('$CIVITAI_API_TOKEN', token)\n",
        "            print('Resolving URL (following redirects)...')\n",
        "            s = requests.Session()\n",
        "            s.headers.update({'User-Agent':'ComfyUI-Playground/1.0'})\n",
        "            try:\n",
        "                r = s.head(url, allow_redirects=True, timeout=20)\n",
        "                if r.status_code >= 400:\n",
        "                    r = s.get(url, stream=True, allow_redirects=True, timeout=20)\n",
        "                    r.close()\n",
        "                final_url = r.url\n",
        "                cd = r.headers.get('Content-Disposition','')\n",
        "                filename = None\n",
        "                if cd:\n",
        "                    m = re.search(r\"filename\\*=UTF-8''(.+)|filename=\\\"?([^\\\";]+)\\\"?\", cd)\n",
        "                    if m:\n",
        "                        filename = m.group(1) or m.group(2)\n",
        "                if not filename:\n",
        "                    filename = final_url.split('/')[-1].split('?')[0]\n",
        "                size = r.headers.get('Content-Length')\n",
        "                if size:\n",
        "                    size = int(size)\n",
        "                else:\n",
        "                    size = None\n",
        "                print('Model', mid)\n",
        "                print('Final URL:', final_url)\n",
        "                print('Filename:', filename)\n",
        "                if size:\n",
        "                    mb = size/1024/1024\n",
        "                    print(f'Content-Length: {size} bytes ({mb:.1f} MB)')\n",
        "                    if mb > 2000:\n",
        "                        print('\\nWARNING: file is very large. Consider running on a VM with enough disk space.')\n",
        "                else:\n",
        "                    print('Content-Length header not present')\n",
        "                # store preview info for confirm\n",
        "                current_preview.update({'mid':mid, 'entry':entry, 'final_url':final_url, 'filename':filename, 'size':size})\n",
        "            except Exception as e:\n",
        "                print('Failed to preview URL:', e)\n",
        "\n",
        "    def on_confirm(b):\n",
        "        with out:\n",
        "            clear_output()\n",
        "            if not current_preview['mid']:\n",
        "                print('No preview available — run Preview first')\n",
        "                return\n",
        "            entry = current_preview['entry']\n",
        "            url = current_preview['final_url']\n",
        "            filename = current_preview['filename']\n",
        "            size = current_preview['size']\n",
        "            # determine download dir\n",
        "            tpl = entry.get('recommended_dir_template','{MODELS_DIR}')\n",
        "            target_dir = Path(expand_dir_template(tpl))\n",
        "            target_dir.mkdir(parents=True, exist_ok=True)\n",
        "            target_path = target_dir/filename\n",
        "            # Stream download\n",
        "            s = requests.Session()\n",
        "            s.headers.update({'User-Agent':'ComfyUI-Playground/1.0'})\n",
        "            print('Starting streaming download to', str(target_path))\n",
        "            try:\n",
        "                r = s.get(url, stream=True, timeout=30)\n",
        "                r.raise_for_status()\n",
        "                total = r.headers.get('Content-Length')\n",
        "                if total:\n",
        "                    total = int(total)\n",
        "                downloaded = 0\n",
        "                with open(target_path, 'wb') as fh:\n",
        "                    for chunk in r.iter_content(chunk_size=1024*1024):\n",
        "                        if chunk:\n",
        "                            fh.write(chunk)\n",
        "                            downloaded += len(chunk)\n",
        "                            if total:\n",
        "                                pct = downloaded/total*100\n",
        "                                print(f'\\rDownloaded {downloaded}/{total} bytes ({pct:.1f}%)', end='')\n",
        "                print('\\nDownload complete')\n",
        "                # update manifest\n",
        "                entry['downloaded_path'] = str(target_path)\n",
        "                manifest[str(current_preview['mid'])] = entry\n",
        "                MANIFEST_PATH.write_text(json.dumps(manifest, indent=2))\n",
        "                print('Manifest updated with downloaded_path')\n",
        "            except Exception as e:\n",
        "                print('Download failed:', e)\n",
        "\n",
        "    preview_btn.on_click(on_preview)\n",
        "    confirm_btn.on_click(on_confirm)\n",
        "\n",
        "    display(dropdown, preview_btn, confirm_btn, out)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "MBnbvOKkw4W5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Unified Colab downloader — queue mode, preview, server-hash pre-check, progress\n",
        "\"\"\"\n",
        "Features:\n",
        "- Queue multiple manifest entries for sequential download with progress.\n",
        "- Preview mode that resolves final filenames and sizes.\n",
        "- Optional server-hash pre-check: if the resolver found a server_hash (ETag or similar), compare\n",
        "  that short hash with a best-effort mapping before downloading.\n",
        "- Uses tqdm for progress display if available, otherwise prints simple progress messages.\n",
        "\n",
        "Usage:\n",
        "- Ensure `CIVITAI_API_TOKEN` is set in this runtime (secure token cell).\n",
        "- Run the resolver cell first to fill resolved_filename and server_hash.\n",
        "- Populate `queue_ids` with manifest keys to download, or use the UI dropdown/selection below.\n",
        "\"\"\"\n",
        "import os, json, re, time, hashlib\n",
        "from pathlib import Path\n",
        "import requests\n",
        "\n",
        "try:\n",
        "    from tqdm.notebook import tqdm\n",
        "    have_tqdm = True\n",
        "except Exception:\n",
        "    have_tqdm = False\n",
        "\n",
        "DRIVE_ROOT = globals().get('DRIVE_ROOT','/content/drive/MyDrive/ComfyUI')\n",
        "MANIFEST_PATH = Path(DRIVE_ROOT)/'manifests'/'civitai_model_manifests.json'\n",
        "\n",
        "if not MANIFEST_PATH.exists():\n",
        "    raise FileNotFoundError(f'Manifest not found at {MANIFEST_PATH}')\n",
        "\n",
        "manifest = json.loads(MANIFEST_PATH.read_text())\n",
        "\n",
        "# Simple helper: choose ids to download. Replace or populate programmatically.\n",
        "# Example: queue_ids = ['1', '2']\n",
        "queue_ids = []\n",
        "\n",
        "# Optional: prefer server hash pre-check (will skip download if mismatch in header-derived simple hash)\n",
        "ENABLE_SERVER_HASH_CHECK = True\n",
        "\n",
        "s = requests.Session()\n",
        "s.headers.update({'User-Agent':'ComfyUI-Playground/1.0'})\n",
        "\n",
        "\n",
        "def compute_sha256(path):\n",
        "    h = hashlib.sha256()\n",
        "    with open(path, 'rb') as fh:\n",
        "        for chunk in iter(lambda: fh.read(1024*1024), b''):\n",
        "            h.update(chunk)\n",
        "    return h.hexdigest()\n",
        "\n",
        "\n",
        "def download_with_progress(url, target_path):\n",
        "    r = s.get(url, stream=True, timeout=30)\n",
        "    r.raise_for_status()\n",
        "    total = r.headers.get('Content-Length')\n",
        "    if total:\n",
        "        total = int(total)\n",
        "    tmp = str(target_path) + '.part'\n",
        "    with open(tmp, 'wb') as fh:\n",
        "        if have_tqdm and total:\n",
        "            with tqdm(total=total, unit='B', unit_scale=True, desc=str(target_path.name)) as pbar:\n",
        "                for chunk in r.iter_content(chunk_size=1024*1024):\n",
        "                    if chunk:\n",
        "                        fh.write(chunk)\n",
        "                        pbar.update(len(chunk))\n",
        "        else:\n",
        "            dl = 0\n",
        "            for chunk in r.iter_content(chunk_size=1024*1024):\n",
        "                if chunk:\n",
        "                    fh.write(chunk)\n",
        "                    dl += len(chunk)\n",
        "    Path(tmp).rename(target_path)\n",
        "    return target_path\n",
        "\n",
        "\n",
        "def server_hash_matches(header_hash, path):\n",
        "    # best-effort: compare ETag (may be quoted or not) to file's MD5/sha256 prefix\n",
        "    if not header_hash:\n",
        "        return None\n",
        "    hh = header_hash.strip('\"')\n",
        "    # If header looks like md5 hex length 32, we can compute md5\n",
        "    if re.fullmatch(r'[0-9a-fA-F]{32}', hh):\n",
        "        import hashlib\n",
        "        m = hashlib.md5()\n",
        "        with open(path, 'rb') as fh:\n",
        "            for chunk in iter(lambda: fh.read(1024*1024), b''):\n",
        "                m.update(chunk)\n",
        "        return m.hexdigest() == hh\n",
        "    # If header looks like a sha256 hex (64 chars)\n",
        "    if re.fullmatch(r'[0-9a-fA-F]{64}', hh):\n",
        "        return compute_sha256(path) == hh\n",
        "    # unknown format — return None meaning \"can't decide\"\n",
        "    return None\n",
        "\n",
        "\n",
        "def run_queue(ids):\n",
        "    token = os.environ.get('CIVITAI_API_TOKEN','')\n",
        "    if not token:\n",
        "        raise RuntimeError('CIVITAI_API_TOKEN not set. Run the secure token cell.')\n",
        "    for mid in ids:\n",
        "        entry = manifest.get(str(mid))\n",
        "        if not entry:\n",
        "            print('Manifest entry missing for', mid)\n",
        "            continue\n",
        "        url_tpl = entry.get('download_url','')\n",
        "        url = url_tpl.replace('$CIVITAI_API_TOKEN', token)\n",
        "        # use resolved_url if present\n",
        "        final_url = entry.get('resolved_url') or url\n",
        "        filename = entry.get('resolved_filename') or final_url.split('/')[-1].split('?')[0]\n",
        "        suggested_tpl = entry.get('recommended_dir_template','{MODELS_DIR}')\n",
        "        mapping = {\n",
        "            '{MODELS_DIR}': globals().get('MODELS_DIR', str(Path(DRIVE_ROOT)/'models')),\n",
        "            '{LORAS_DIR}': globals().get('LORAS_DIR', str(Path(DRIVE_ROOT)/'models'/'loras')),\n",
        "            '{GGUF_DIR}': globals().get('GGUF_DIR', str(Path(DRIVE_ROOT)/'models'/'gguf')),\n",
        "            '{ARTIFACTS_DIR}': globals().get('ARTIFACTS_DIR', str(Path(DRIVE_ROOT)/'artifacts')),\n",
        "        }\n",
        "        for k,v in mapping.items():\n",
        "            suggested_tpl = suggested_tpl.replace(k,v)\n",
        "        target_dir = Path(suggested_tpl)\n",
        "        target_dir.mkdir(parents=True, exist_ok=True)\n",
        "        target_path = target_dir/filename\n",
        "        # preview info\n",
        "        print(f'Downloading {mid} -> {filename}')\n",
        "        # if server hash exists and check enabled, we'll fetch headers and compare quickly after download\n",
        "        header_hash = entry.get('server_hash')\n",
        "        try:\n",
        "            download_with_progress(final_url, target_path)\n",
        "            sha = compute_sha256(target_path)\n",
        "            entry['downloaded_path'] = str(target_path)\n",
        "            entry['sha256'] = sha\n",
        "            entry['file_size_bytes'] = target_path.stat().st_size\n",
        "            # optional: post-download server-hash compare\n",
        "            if ENABLE_SERVER_HASH_CHECK and header_hash:\n",
        "                match = None\n",
        "                try:\n",
        "                    match = server_hash_matches(header_hash, target_path)\n",
        "                except Exception as e:\n",
        "                    print('Server-hash compare failed:', e)\n",
        "                if match is False:\n",
        "                    entry.setdefault('integrity',{})\n",
        "                    entry['integrity']['server_hash'] = header_hash\n",
        "                    entry['integrity']['server_hash_match'] = False\n",
        "                    entry['download_status'] = 'server_hash_mismatch'\n",
        "                    print('Warning: server hash mismatch for', mid)\n",
        "                else:\n",
        "                    entry.setdefault('integrity',{})\n",
        "                    entry['integrity']['server_hash'] = header_hash\n",
        "                    entry['integrity']['server_hash_match'] = True if match is True else 'unknown'\n",
        "            else:\n",
        "                entry['download_status'] = 'ok'\n",
        "            manifest[str(mid)] = entry\n",
        "            MANIFEST_PATH.write_text(json.dumps(manifest, indent=2))\n",
        "            print('Downloaded and recorded:', target_path)\n",
        "        except Exception as e:\n",
        "            print('Failed to download', mid, e)\n",
        "\n",
        "# If you want a small UI-based queue selector (Colab 'widgets' or ipywidgets), you can implement\n",
        "# here; for now, run programmatically by setting queue_ids and calling run_queue(queue_ids)\n",
        "\n",
        "print('Manifest keys available:', list(manifest.keys())[:20])\n",
        "print('Set queue_ids = [\"1\",\"2\"] and call run_queue(queue_ids)')\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "YIxvUxMAt_TE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Colab-friendly interactive downloader (uses google.colab widgets when available)\n",
        "\"\"\"\n",
        "This cell provides a Colab-optimized UI for the interactive download runner.\n",
        "It prefers Google Colab's native widget layer when available; otherwise it falls\n",
        "back to ipywidgets. Behavior is similar to the earlier interactive runner:\n",
        "- Select a model from manifest\n",
        "- Preview final filename/size\n",
        "- Confirm to download (stream into Drive)\n",
        "\n",
        "Run after mounting Drive and setting CIVITAI_API_TOKEN via the secure input cell.\n",
        "\"\"\"\n",
        "import os, json, re, requests\n",
        "from pathlib import Path\n",
        "import hashlib\n",
        "\n",
        "# UI imports (prefer google.colab widgets if available)\n",
        "use_colab_widgets = False\n",
        "try:\n",
        "    import google.colab.widgets as colab_widgets\n",
        "    from google.colab import output as colab_output\n",
        "    use_colab_widgets = True\n",
        "except Exception:\n",
        "    try:\n",
        "        import ipywidgets as widgets\n",
        "        from IPython.display import display, clear_output\n",
        "        use_colab_widgets = False\n",
        "    except Exception:\n",
        "        raise RuntimeError('No UI widget library available (need google.colab or ipywidgets)')\n",
        "\n",
        "DRIVE_ROOT = globals().get('DRIVE_ROOT','/content/drive/MyDrive/ComfyUI')\n",
        "MANIFEST_PATH = Path(DRIVE_ROOT)/'manifests'/'civitai_model_manifests.json'\n",
        "\n",
        "if not MANIFEST_PATH.exists():\n",
        "    print('Manifest not found at', MANIFEST_PATH)\n",
        "else:\n",
        "    manifest = json.loads(MANIFEST_PATH.read_text())\n",
        "    keys = sorted(manifest.keys(), key=lambda x:int(x))\n",
        "\n",
        "    def expand_dir_template(tpl):\n",
        "        mapping = {\n",
        "            '{MODELS_DIR}': globals().get('MODELS_DIR', str(Path(DRIVE_ROOT)/'models')),\n",
        "            '{LORAS_DIR}': globals().get('LORAS_DIR', str(Path(DRIVE_ROOT)/'models'/'loras')),\n",
        "            '{GGUF_DIR}': globals().get('GGUF_DIR', str(Path(DRIVE_ROOT)/'models'/'gguf')),\n",
        "            '{ARTIFACTS_DIR}': globals().get('ARTIFACTS_DIR', str(Path(DRIVE_ROOT)/'artifacts')),\n",
        "        }\n",
        "        for k,v in mapping.items():\n",
        "            tpl = tpl.replace(k, v)\n",
        "        return tpl\n",
        "\n",
        "    # Common preview & download functions\n",
        "    def resolve_preview(mid):\n",
        "        entry = manifest.get(str(mid))\n",
        "        token = os.environ.get('CIVITAI_API_TOKEN','')\n",
        "        if not token:\n",
        "            return {'error':'CIVITAI_API_TOKEN not set'}\n",
        "        url = entry.get('download_url','').replace('$CIVITAI_API_TOKEN', token)\n",
        "        s = requests.Session()\n",
        "        s.headers.update({'User-Agent':'ComfyUI-Playground/1.0'})\n",
        "        try:\n",
        "            r = s.head(url, allow_redirects=True, timeout=20)\n",
        "            if r.status_code >= 400:\n",
        "                r = s.get(url, stream=True, allow_redirects=True, timeout=20)\n",
        "                r.close()\n",
        "            final_url = r.url\n",
        "            cd = r.headers.get('Content-Disposition','')\n",
        "            filename = None\n",
        "            if cd:\n",
        "                m = re.search(r\"filename\\*=UTF-8''(.+)|filename=\\\"?([^\\\";]+)\\\"?\", cd)\n",
        "                if m:\n",
        "                    filename = m.group(1) or m.group(2)\n",
        "            if not filename:\n",
        "                filename = final_url.split('/')[-1].split('?')[0]\n",
        "            size = r.headers.get('Content-Length')\n",
        "            if size:\n",
        "                size = int(size)\n",
        "            return {'final_url': final_url, 'filename': filename, 'size': size}\n",
        "        except Exception as e:\n",
        "            return {'error': str(e)}\n",
        "\n",
        "    def stream_download(final_url, target_path):\n",
        "        s = requests.Session()\n",
        "        s.headers.update({'User-Agent':'ComfyUI-Playground/1.0'})\n",
        "        r = s.get(final_url, stream=True, timeout=30)\n",
        "        r.raise_for_status()\n",
        "        downloaded = 0\n",
        "        total = r.headers.get('Content-Length')\n",
        "        if total:\n",
        "            total = int(total)\n",
        "        with open(target_path, 'wb') as fh:\n",
        "            for chunk in r.iter_content(chunk_size=1024*1024):\n",
        "                if chunk:\n",
        "                    fh.write(chunk)\n",
        "                    downloaded += len(chunk)\n",
        "        return target_path\n",
        "\n",
        "    # Build UI depending on environment\n",
        "    if use_colab_widgets:\n",
        "        # very small colab-friendly UI using simple text inputs and buttons\n",
        "        options = [(f\"{k}  -> {manifest[k].get('resolved_filename','?')}\", k) for k in keys]\n",
        "        dd = colab_widgets.Dropdown(options=options, description='Model')\n",
        "        preview_btn = colab_widgets.Button(description='Preview')\n",
        "        download_btn = colab_widgets.Button(description='Confirm & Download')\n",
        "        status_area = colab_widgets.Textarea(value='Ready', description='Status', layout={'width':'100%'})\n",
        "\n",
        "        def on_preview(widget, event=None):\n",
        "            mid = dd.value\n",
        "            status_area.value = 'Resolving...'\n",
        "            res = resolve_preview(mid)\n",
        "            if 'error' in res:\n",
        "                status_area.value = 'Error: ' + res['error']\n",
        "            else:\n",
        "                size = res['size']\n",
        "                stext = f\"Filename: {res['filename']}\\nURL: {res['final_url']}\\n\"\n",
        "                if size:\n",
        "                    stext += f\"Size: {size} bytes ({size/1024/1024:.1f} MB)\\n\"\n",
        "                status_area.value = stext\n",
        "                # stash preview info in widget attrs\n",
        "                dd._preview = res\n",
        "\n",
        "        def on_download(widget, event=None):\n",
        "            if not hasattr(dd, '_preview'):\n",
        "                status_area.value = 'Run Preview first'\n",
        "                return\n",
        "            res = dd._preview\n",
        "            filename = res['filename']\n",
        "            final_url = res['final_url']\n",
        "            entry = manifest.get(str(dd.value))\n",
        "            tpl = entry.get('recommended_dir_template','{MODELS_DIR}')\n",
        "            target_dir = Path(expand_dir_template(tpl))\n",
        "            target_dir.mkdir(parents=True, exist_ok=True)\n",
        "            target_path = target_dir/filename\n",
        "            status_area.value = f'Starting download to {target_path}\\n'\n",
        "            try:\n",
        "                stream_download(final_url, str(target_path))\n",
        "                status_area.value += 'Download complete\\nComputing SHA256...'\n",
        "                # compute sha256\n",
        "                h = hashlib.sha256()\n",
        "                with open(target_path, 'rb') as fh:\n",
        "                    for chunk in iter(lambda: fh.read(1024*1024), b''):\n",
        "                        h.update(chunk)\n",
        "                sha = h.hexdigest()\n",
        "                entry['downloaded_path'] = str(target_path)\n",
        "                entry['sha256'] = sha\n",
        "                entry['file_size_bytes'] = target_path.stat().st_size\n",
        "                manifest[str(dd.value)] = entry\n",
        "                MANIFEST_PATH.write_text(json.dumps(manifest, indent=2))\n",
        "                status_area.value += f\"\\nSHA256: {sha}\\nSaved and manifest updated.\"\n",
        "            except Exception as e:\n",
        "                status_area.value += '\\nDownload failed: ' + str(e)\n",
        "\n",
        "        preview_btn.on_click(lambda w: on_preview(w))\n",
        "        download_btn.on_click(lambda w: on_download(w))\n",
        "        display(dd, preview_btn, download_btn, status_area)\n",
        "\n",
        "    else:\n",
        "        # fallback to ipywidgets UI (previous behavior)\n",
        "        import ipywidgets as widgets\n",
        "        from IPython.display import display, clear_output\n",
        "        options = []\n",
        "        for k in keys:\n",
        "            label = f\"{k}: {manifest[k].get('suggested_formats')}\"\n",
        "            if manifest[k].get('resolved_filename'):\n",
        "                label += f\" -> {manifest[k].get('resolved_filename')}\"\n",
        "            options.append((label,k))\n",
        "        dropdown = widgets.Dropdown(options=options, description='Model:')\n",
        "        preview_btn = widgets.Button(description='Preview')\n",
        "        confirm_btn = widgets.Button(description='Confirm & Download', button_style='danger')\n",
        "        out = widgets.Output()\n",
        "\n",
        "        current_preview = {'mid':None, 'entry':None, 'final_url':None, 'filename':None, 'size':None}\n",
        "\n",
        "        def on_preview(b):\n",
        "            with out:\n",
        "                clear_output()\n",
        "                mid = dropdown.value\n",
        "                entry = manifest.get(str(mid))\n",
        "                if not entry:\n",
        "                    print('Manifest entry not found for', mid)\n",
        "                    return\n",
        "                token = os.environ.get('CIVITAI_API_TOKEN','')\n",
        "                if not token:\n",
        "                    print('CIVITAI_API_TOKEN not set. Run the secure token cell first.')\n",
        "                    return\n",
        "                url = entry.get('download_url','').replace('$CIVITAI_API_TOKEN', token)\n",
        "                print('Resolving URL (following redirects)...')\n",
        "                s = requests.Session()\n",
        "                s.headers.update({'User-Agent':'ComfyUI-Playground/1.0'})\n",
        "                try:\n",
        "                    r = s.head(url, allow_redirects=True, timeout=20)\n",
        "                    if r.status_code >= 400:\n",
        "                        r = s.get(url, stream=True, allow_redirects=True, timeout=20)\n",
        "                        r.close()\n",
        "                    final_url = r.url\n",
        "                    cd = r.headers.get('Content-Disposition','')\n",
        "                    filename = None\n",
        "                    if cd:\n",
        "                        m = re.search(r\"filename\\*=UTF-8''(.+)|filename=\\\"?([^\\\";]+)\\\"?\", cd)\n",
        "                        if m:\n",
        "                            filename = m.group(1) or m.group(2)\n",
        "                    if not filename:\n",
        "                        filename = final_url.split('/')[-1].split('?')[0]\n",
        "                    size = r.headers.get('Content-Length')\n",
        "                    if size:\n",
        "                        size = int(size)\n",
        "                    print('Model', mid)\n",
        "                    print('Final URL:', final_url)\n",
        "                    print('Filename:', filename)\n",
        "                    if size:\n",
        "                        mb = size/1024/1024\n",
        "                        print(f'Content-Length: {size} bytes ({mb:.1f} MB)')\n",
        "                    else:\n",
        "                        print('Content-Length header not present')\n",
        "                    current_preview.update({'mid':mid, 'entry':entry, 'final_url':final_url, 'filename':filename, 'size':size})\n",
        "                except Exception as e:\n",
        "                    print('Failed to preview URL:', e)\n",
        "\n",
        "        def on_confirm(b):\n",
        "            with out:\n",
        "                clear_output()\n",
        "                if not current_preview['mid']:\n",
        "                    print('No preview available — run Preview first')\n",
        "                    return\n",
        "                entry = current_preview['entry']\n",
        "                url = current_preview['final_url']\n",
        "                filename = current_preview['filename']\n",
        "                tpl = entry.get('recommended_dir_template','{MODELS_DIR}')\n",
        "                target_dir = Path(expand_dir_template(tpl))\n",
        "                target_dir.mkdir(parents=True, exist_ok=True)\n",
        "                target_path = target_dir/filename\n",
        "                print('Starting streaming download to', str(target_path))\n",
        "                try:\n",
        "                    r = requests.get(url, stream=True, timeout=30)\n",
        "                    r.raise_for_status()\n",
        "                    with open(target_path, 'wb') as fh:\n",
        "                        for chunk in r.iter_content(chunk_size=1024*1024):\n",
        "                            if chunk:\n",
        "                                fh.write(chunk)\n",
        "                    print('Download complete — computing SHA256...')\n",
        "                    # compute sha256\n",
        "                    h = hashlib.sha256()\n",
        "                    with open(target_path, 'rb') as fh:\n",
        "                        for chunk in iter(lambda: fh.read(1024*1024), b''):\n",
        "                            h.update(chunk)\n",
        "                    sha = h.hexdigest()\n",
        "                    entry['downloaded_path'] = str(target_path)\n",
        "                    entry['sha256'] = sha\n",
        "                    entry['file_size_bytes'] = target_path.stat().st_size\n",
        "                    manifest[str(current_preview['mid'])] = entry\n",
        "                    MANIFEST_PATH.write_text(json.dumps(manifest, indent=2))\n",
        "                    print('SHA256:', sha)\n",
        "                    print('Manifest updated with downloaded_path and sha256')\n",
        "                except Exception as e:\n",
        "                    print('Download failed:', e)\n",
        "\n",
        "        preview_btn.on_click(on_preview)\n",
        "        confirm_btn.on_click(on_confirm)\n",
        "        display(dropdown, preview_btn, confirm_btn, out)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "vImV8iyQwtAV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Post-download integrity checker & download summary\n",
        "\"\"\"\n",
        "Scans the manifest for entries with `downloaded_path`, computes/validates SHA256 if present,\n",
        "records any mismatches, and produces a simple download_summary.json with totals.\n",
        "Run after you have performed downloads with the interactive downloader.\n",
        "\"\"\"\n",
        "import json, os, hashlib\n",
        "from pathlib import Path\n",
        "\n",
        "DRIVE_ROOT = globals().get('DRIVE_ROOT','/content/drive/MyDrive/ComfyUI')\n",
        "MANIFEST_PATH = Path(DRIVE_ROOT)/'manifests'/'civitai_model_manifests.json'\n",
        "SUMMARY_PATH = Path(DRIVE_ROOT)/'manifests'/'download_summary.json'\n",
        "\n",
        "if not MANIFEST_PATH.exists():\n",
        "    print('Manifest not found at', MANIFEST_PATH)\n",
        "else:\n",
        "    manifest = json.loads(MANIFEST_PATH.read_text())\n",
        "    summary = {\n",
        "        'total_files': 0,\n",
        "        'total_bytes': 0,\n",
        "        'entries': {}\n",
        "    }\n",
        "    for mid,entry in manifest.items():\n",
        "        dp = entry.get('downloaded_path')\n",
        "        if not dp:\n",
        "            continue\n",
        "        p = Path(dp)\n",
        "        if not p.exists():\n",
        "            entry['download_status'] = 'missing'\n",
        "            manifest[mid] = entry\n",
        "            continue\n",
        "        size = p.stat().st_size\n",
        "        sha_expected = entry.get('sha256')\n",
        "        # compute sha\n",
        "        h = hashlib.sha256()\n",
        "        with open(p, 'rb') as fh:\n",
        "            for chunk in iter(lambda: fh.read(1024*1024), b''):\n",
        "                h.update(chunk)\n",
        "        sha_actual = h.hexdigest()\n",
        "        ok = True\n",
        "        if sha_expected and sha_expected != sha_actual:\n",
        "            entry.setdefault('integrity',{})\n",
        "            entry['integrity']['expected_sha256'] = sha_expected\n",
        "            entry['integrity']['actual_sha256'] = sha_actual\n",
        "            entry['download_status'] = 'sha_mismatch'\n",
        "            ok = False\n",
        "        else:\n",
        "            entry.setdefault('integrity',{})\n",
        "            entry['integrity']['actual_sha256'] = sha_actual\n",
        "            entry['download_status'] = 'ok'\n",
        "        entry['file_size_bytes'] = size\n",
        "        manifest[mid] = entry\n",
        "\n",
        "        summary['total_files'] += 1\n",
        "        summary['total_bytes'] += size\n",
        "        summary['entries'][mid] = {\n",
        "            'path': str(p),\n",
        "            'size_bytes': size,\n",
        "            'sha256': sha_actual,\n",
        "            'status': entry.get('download_status')\n",
        "        }\n",
        "\n",
        "    MANIFEST_PATH.write_text(json.dumps(manifest, indent=2))\n",
        "    SUMMARY_PATH.write_text(json.dumps(summary, indent=2))\n",
        "    print('Integrity check complete. Files:', summary['total_files'], 'Total bytes:', summary['total_bytes'])\n",
        "    print('Summary written to', SUMMARY_PATH)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "K1V4rCfAwF-i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Download summary UI — show totals and top N largest files\n",
        "\"\"\"\n",
        "Displays the download_summary.json created by the integrity checker in a friendly format.\n",
        "Shows total files, total size, and the top-N largest downloaded files.\n",
        "\"\"\"\n",
        "import json, math\n",
        "from pathlib import Path\n",
        "\n",
        "DRIVE_ROOT = globals().get('DRIVE_ROOT','/content/drive/MyDrive/ComfyUI')\n",
        "SUMMARY_PATH = Path(DRIVE_ROOT)/'manifests'/'download_summary.json'\n",
        "\n",
        "if not SUMMARY_PATH.exists():\n",
        "    print('No download_summary.json found. Run the Post-download integrity checker cell first.')\n",
        "else:\n",
        "    data = json.loads(SUMMARY_PATH.read_text())\n",
        "    total_files = data.get('total_files',0)\n",
        "    total_bytes = data.get('total_bytes',0)\n",
        "    def human(n):\n",
        "        for u in ['B','KB','MB','GB','TB']:\n",
        "            if n < 1024:\n",
        "                return f\"{n:.2f}{u}\"\n",
        "            n /= 1024\n",
        "        return f\"{n:.2f}PB\"\n",
        "    print('Downloaded files:', total_files)\n",
        "    print('Total size:', human(total_bytes))\n",
        "    entries = data.get('entries',{})\n",
        "    items = []\n",
        "    for mid,info in entries.items():\n",
        "        size = info.get('size_bytes',0)\n",
        "        items.append((size, mid, info.get('path')))\n",
        "    items.sort(reverse=True)\n",
        "    topn = 10\n",
        "    print('\\nTop files:')\n",
        "    for i,(size, mid, path) in enumerate(items[:topn], start=1):\n",
        "        print(f\"{i}. {mid} — {human(size)} — {path}\")\n",
        "    if len(items) > topn:\n",
        "        print(f\"... and {len(items)-topn} more files\")\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "rNT4uW2jwXPu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## README (quick-run instructions)\n",
        "\n",
        "This cell is a short-run README making the key steps explicit. Use it as a quick checklist.\n",
        "\n",
        "1. Mount Google Drive (run the Drive mount cell) and ensure `DRIVE_ROOT` is set to your ComfyUI directory, e.g. `/content/drive/MyDrive/ComfyUI`.\n",
        "2. Run the secure token input cell to put `CIVITAI_API_TOKEN` (and optionally AWS/GCS creds) in environment variables.\n",
        "3. Run the Manifest locator helper if your manifest isn't at the default path.\n",
        "4. Run the Batch manifest resolver to populate `resolved_filename` and `server_hash` fields.\n",
        "5. Use the HTML \"Downloader Panel\" cell below to select entries, Start the queue, monitor progress, and Stop/Cancel if needed.\n",
        "6. After downloads, run the Post-download integrity checker cell and then the Download summary UI cell.\n",
        "\n",
        "Notes:\n",
        "- The HTML panel sends selections to Python callbacks in this notebook. Progress and logs appear in the Python output area. Live updates inside the HTML panel are limited by Colab cross-call constraints, so the Python output is the authoritative log.\n",
        "- Background scheduler: there's a cell below that can run the resolver periodically (for automated refresh). Be careful: Colab sessions can time out; only run this if your session will remain active.\n",
        "\n"
      ],
      "metadata": {
        "id": "KBvNFdmYyU12"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Downloader Panel (HTML multi-select + Start/Stop callbacks)\n",
        "\"\"\"\n",
        "Renders an HTML panel with checkboxes for manifest entries and Start/Stop buttons.\n",
        "On Start it invokes the registered python callback to start the background download worker with selected ids.\n",
        "\"\"\"\n",
        "import json, os\n",
        "from pathlib import Path\n",
        "from google.colab import output\n",
        "\n",
        "DRIVE_ROOT = globals().get('DRIVE_ROOT','/content/drive/MyDrive/ComfyUI')\n",
        "MANIFEST_PATH = Path(DRIVE_ROOT)/'manifests'/'civitai_model_manifests.json'\n",
        "\n",
        "if not MANIFEST_PATH.exists():\n",
        "    print('Manifest not found at', MANIFEST_PATH)\n",
        "    print('Run the Manifest locator helper to locate or copy the manifest to the expected path.')\n",
        "else:\n",
        "    manifest = json.loads(MANIFEST_PATH.read_text())\n",
        "    # build a simple table\n",
        "    rows = []\n",
        "    for k, entry in sorted(manifest.items(), key=lambda t: int(t[0])):\n",
        "        name = entry.get('resolved_filename') or entry.get('title') or entry.get('name') or f'model-{k}'\n",
        "        size = entry.get('content_length') or entry.get('file_size_bytes') or ''\n",
        "        rows.append({'id':k,'label':str(name),'size':size})\n",
        "\n",
        "    html_rows = '\\n'.join([f\"<div><label><input type=checkbox value='{r['id']}' /> {r['label']} <small>{r['size']}</small></label></div>\" for r in rows])\n",
        "\n",
        "    panel = f\"\"\"\n",
        "    <div style='font-family: Roboto, Arial, sans-serif; padding: 8px; border: 1px solid #ddd; border-radius: 6px; width: 100%'>\n",
        "      <h3>Downloader Panel</h3>\n",
        "      <div id='manifest-list' style='max-height:300px; overflow:auto; padding:6px'>{html_rows}</div>\n",
        "      <div style='margin-top:8px'>\n",
        "        <button id='start-btn' style='padding:6px 12px; background:#0b74de; color:white; border:none; border-radius:4px'>Start Queue</button>\n",
        "        <button id='stop-btn' style='padding:6px 12px; margin-left:8px; background:#d9534f; color:white; border:none; border-radius:4px'>Stop Queue</button>\n",
        "        <label style='margin-left:12px'><input type='checkbox' id='retry-check' /> Enable retries</label>\n",
        "        <label style='margin-left:12px'>Retries: <input id='retry-count' type='number' value='2' style='width:60px'></label>\n",
        "      </div>\n",
        "      <div id='panel-status' style='margin-top:10px; font-size:0.9em; color:#333'></div>\n",
        "    </div>\n",
        "    <script>\n",
        "    const getChecked = () => Array.from(document.querySelectorAll('#manifest-list input:checked')).map(x=>x.value);\n",
        "    document.getElementById('start-btn').onclick = () => {\n",
        "        const ids = getChecked();\n",
        "        const retry = document.getElementById('retry-check').checked;\n",
        "        const rcount = parseInt(document.getElementById('retry-count').value || '2');\n",
        "        document.getElementById('panel-status').innerText = 'Starting queue: ' + ids.join(', ');\n",
        "        google.colab.kernel.invokeFunction('notebook.start_queue', [ids, retry, rcount], {});\n",
        "    };\n",
        "    document.getElementById('stop-btn').onclick = () => {\n",
        "        document.getElementById('panel-status').innerText = 'Stopping queue...';\n",
        "        google.colab.kernel.invokeFunction('notebook.stop_queue', [], {});\n",
        "    };\n",
        "    </script>\n",
        "    \"\"\"\n",
        "    output.eval_js('console.clear()')\n",
        "    display_html = output._repr_html_(panel)\n",
        "    display(display_html)\n",
        "\n",
        "# Register callbacks — the actual implementation is provided in the Background worker cell below\n",
        "\n",
        "def _no_op(*args, **kwargs):\n",
        "    print('Callback not registered yet')\n",
        "\n",
        "# register placeholder so kernel.invokeFunction calls won't fail if background worker not loaded\n",
        "output.register_callback('notebook.start_queue', _no_op)\n",
        "output.register_callback('notebook.stop_queue', _no_op)\n",
        "print('Downloader Panel rendered. Use the checkboxes, then Start Queue. Logs will appear in the Python output area.')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "mJtdOdjOySm_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Downloader Dashboard — rich HTML UI with per-item progress\n",
        "\"\"\"\n",
        "Renders a richer HTML dashboard that polls `notebook.get_queue_status` for per-item progress\n",
        "and displays progress bars. It also exposes Start/Stop and retry controls.\n",
        "\n",
        "Note: polling frequency is limited to avoid spamming the kernel. The authoritative logs\n",
        "and the final state are saved to DRIVE_ROOT/.queue_state.json — the UI reflects that state.\n",
        "\"\"\"\n",
        "from google.colab import output\n",
        "from IPython.display import display, HTML\n",
        "import json\n",
        "\n",
        "DRIVE_ROOT = globals().get('DRIVE_ROOT','/content/drive/MyDrive/ComfyUI')\n",
        "MANIFEST_PATH = f\"{DRIVE_ROOT}/manifests/civitai_model_manifests.json\"\n",
        "\n",
        "# Build the HTML template with a placeholder for the list; the UI will ask Python for the manifest\n",
        "html = r'''\n",
        "<div style=\"font-family: Roboto, Arial; padding:10px; border:1px solid #ddd; border-radius:6px;\">\n",
        "  <h3>Downloader Dashboard</h3>\n",
        "  <div style=\"margin-bottom:8px\">\n",
        "    <button id=\"dd-start\">Start Selected</button>\n",
        "    <button id=\"dd-stop\">Stop</button>\n",
        "    <label style=\"margin-left:10px\">Retries: <input id=\"dd-retries\" type=\"number\" value=\"2\" style=\"width:50px\"></label>\n",
        "  </div>\n",
        "  <div id=\"dd-list\" style=\"max-height:360px; overflow:auto; border-top:1px solid #eee; padding-top:8px\"></div>\n",
        "  <div id=\"dd-status\" style=\"margin-top:8px; font-size:0.9em; color:#333\"></div>\n",
        "</div>\n",
        "<script>\n",
        "async function fetchManifest() {\n",
        "  // request the Python side for current manifest keys + resolved filenames\n",
        "  const resp = await google.colab.kernel.invokeFunction('notebook.get_queue_status', [], {});\n",
        "  const state = resp.data['application/json'];\n",
        "  const items = state.items || {};\n",
        "  const list = document.getElementById('dd-list');\n",
        "  list.innerHTML = '';\n",
        "  for (const id of Object.keys(items)){\n",
        "    const it = items[id];\n",
        "    const div = document.createElement('div');\n",
        "    div.style.padding = '6px 4px';\n",
        "    div.style.borderBottom = '1px solid #f4f4f4';\n",
        "    const title = document.createElement('div');\n",
        "    title.innerHTML = `<strong>${id}</strong> — ${it.filename || ''}`;\n",
        "    div.appendChild(title);\n",
        "    const bar = document.createElement('div');\n",
        "    bar.style.height = '10px';\n",
        "    bar.style.width = '100%';\n",
        "    bar.style.background = '#eee';\n",
        "    bar.style.borderRadius = '6px';\n",
        "    const inner = document.createElement('div');\n",
        "    inner.style.height = '100%';\n",
        "    inner.style.width = (it.percent? it.percent+'%': '0%');\n",
        "    inner.style.background = (it.status==='ok'? '#4caf50' : (it.status==='failed'? '#d9534f' : '#0b74de'));\n",
        "    inner.style.borderRadius = '6px';\n",
        "    inner.style.transition = 'width 0.4s ease';\n",
        "    bar.appendChild(inner);\n",
        "    div.appendChild(bar);\n",
        "    const meta = document.createElement('div');\n",
        "    meta.style.fontSize='0.85em';\n",
        "    meta.style.color='#666';\n",
        "    meta.innerText = `Status: ${it.status || 'n/a'} | Attempts: ${it.attempts || 0} | ${it.bytes || 0}/${it.bytes_total || 0}`;\n",
        "    div.appendChild(meta);\n",
        "    list.appendChild(div);\n",
        "  }\n",
        "}\n",
        "\n",
        "// initial poll\n",
        "fetchManifest();\n",
        "// poll periodically\n",
        "setInterval(fetchManifest, 2000);\n",
        "\n",
        "// start/stop handlers with simple selection of queued ids (transition: select all with status queued)\n",
        "document.getElementById('dd-start').onclick = async () => {\n",
        "  const reps = await google.colab.kernel.invokeFunction('notebook.get_queue_status', [], {});\n",
        "  const st = reps.data['application/json'];\n",
        "  const ids = Object.keys(st.items || {});\n",
        "  const retries = parseInt(document.getElementById('dd-retries').value || '2');\n",
        "  google.colab.kernel.invokeFunction('notebook.start_queue', [ids, true, retries], {});\n",
        "  document.getElementById('dd-status').innerText = 'Started queue for ids: ' + ids.join(', ');\n",
        "};\n",
        "\n",
        "document.getElementById('dd-stop').onclick = () => {\n",
        "  google.colab.kernel.invokeFunction('notebook.stop_queue', [], {});\n",
        "  document.getElementById('dd-status').innerText = 'Stop requested';\n",
        "};\n",
        "</script>\n",
        "'''\n",
        "\n",
        "display(HTML(html))\n",
        "print('Downloader Dashboard rendered — it polls queue state and shows progress bars. Use Start/Stop to control the worker.')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "VYg4CfGayvtM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "3Ti5mNAyt7-v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Guarded subprocess utilities (replace shell-magic with subprocess wrappers)\n",
        "\"\"\"\n",
        "Provides helper functions to run shell commands in a guarded way so static checkers\n",
        "and Python linters don't complain about Jupyter bang (!) commands. These helpers\n",
        "capture stdout/stderr, enforce timeouts, and optionally run as background processes.\n",
        "\"\"\"\n",
        "import subprocess, shlex, threading, time\n",
        "from pathlib import Path\n",
        "\n",
        "\n",
        "def run_cmd(cmd, timeout=600, shell=False, env=None, cwd=None):\n",
        "    \"\"\"Run a command and return (returncode, stdout, stderr).\"\"\"\n",
        "    if isinstance(cmd, str) and not shell:\n",
        "        cmd = shlex.split(cmd)\n",
        "    proc = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True, env=env, cwd=cwd, shell=shell)\n",
        "    try:\n",
        "        out, err = proc.communicate(timeout=timeout)\n",
        "    except subprocess.TimeoutExpired:\n",
        "        proc.kill()\n",
        "        out, err = proc.communicate()\n",
        "        return proc.returncode or -9, out, err\n",
        "    return proc.returncode, out, err\n",
        "\n",
        "\n",
        "def run_cmd_background(cmd, on_stdout=None, on_stderr=None, env=None, cwd=None):\n",
        "    \"\"\"Run a command in background and stream stdout/stderr to callbacks.\n",
        "    Returns a handle with a terminate() method.\"\"\"\n",
        "    if isinstance(cmd, str):\n",
        "        cmd = shlex.split(cmd)\n",
        "    proc = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True, env=env, cwd=cwd)\n",
        "    stopped = {'stop': False}\n",
        "\n",
        "    def reader(pipe, cb):\n",
        "        try:\n",
        "            for line in iter(pipe.readline, ''):\n",
        "                if cb:\n",
        "                    cb(line)\n",
        "                if stopped['stop']:\n",
        "                    break\n",
        "        finally:\n",
        "            pipe.close()\n",
        "\n",
        "    t_out = threading.Thread(target=reader, args=(proc.stdout, on_stdout), daemon=True)\n",
        "    t_err = threading.Thread(target=reader, args=(proc.stderr, on_stderr), daemon=True)\n",
        "    t_out.start(); t_err.start()\n",
        "\n",
        "    def terminate():\n",
        "        stopped['stop'] = True\n",
        "        try:\n",
        "            proc.terminate()\n",
        "        except Exception:\n",
        "            pass\n",
        "    return {'proc': proc, 'terminate': terminate}\n",
        "\n",
        "print('Guarded subprocess utilities loaded (run_cmd, run_cmd_background)')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "ox21w1ysy-z4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "L6AhMp9PzA6q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "X6XRnsiOzCl7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **WAN IMAGE TO VIDEO WITH Q4 & Q6 GGUF MODELS**\n",
        "- You can use the free T4 GPU to run this notebook with the default Q4 GGUF model. I recommend that you use higher GPUs for the Q6 GGUF model. This is the link to the main huggingface repository of the I2V 14B-480p GGUF models: https://huggingface.co/city96/Wan2.1-I2V-14B-480P-gguf/tree/main\n",
        "- Generating a video from this flux image (https://comfyanonymous.github.io/ComfyUI_examples/flux/) with the default settings (512x512, 20 steps, 49 frames) using the Q4 GGUF model and the free T4 GPU took about 26 minutes.\n",
        "- Generating a video from a 720x1280 Image with a setting of 480x832, 20 steps, and 33 frames using the Q4 GGUF model and the free T4 GPU took 26 minutes 30 seconds. Generating the same video using the Q6 GGUF model and the L4 GPU took 10 minutes 10 seconds.\n",
        "- The videos are generated at 16fps. You can use the `Frame Interpolation` notebook in this github repository (https://github.com/Isi-dev/Google-Colab_Notebooks) to increase it."
      ],
      "metadata": {
        "id": "_2gwCJ8f3mjA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t089iwSddWDL",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title Prepare WAN Environment\n",
        "!pip install torch==2.6.0 torchvision==0.21.0\n",
        "%cd /content\n",
        "\n",
        "!pip install -q torchsde einops diffusers accelerate xformers==0.0.29.post2\n",
        "!pip install av\n",
        "!git clone https://github.com/Isi-dev/ComfyUI\n",
        "%cd /content/ComfyUI/custom_nodes\n",
        "!git clone https://github.com/Isi-dev/ComfyUI_GGUF.git\n",
        "%cd /content/ComfyUI/custom_nodes/ComfyUI_GGUF\n",
        "!pip install -r requirements.txt\n",
        "%cd /content/ComfyUI\n",
        "!apt -y install -qq aria2 ffmpeg\n",
        "\n",
        "useQ6 = False # @param {\"type\":\"boolean\"}\n",
        "\n",
        "if useQ6:\n",
        "    !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/city96/Wan2.1-I2V-14B-480P-gguf/resolve/main/wan2.1-i2v-14b-480p-Q6_K.gguf -d /content/ComfyUI/models/unet -o wan2.1-i2v-14b-480p-Q6_K.gguf\n",
        "else:\n",
        "    !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/city96/Wan2.1-I2V-14B-480P-gguf/resolve/main/wan2.1-i2v-14b-480p-Q4_0.gguf -d /content/ComfyUI/models/unet -o wan2.1-i2v-14b-480p-Q4_0.gguf\n",
        "\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/Comfy-Org/Wan_2.1_ComfyUI_repackaged/resolve/main/split_files/text_encoders/umt5_xxl_fp8_e4m3fn_scaled.safetensors -d /content/ComfyUI/models/text_encoders -o umt5_xxl_fp8_e4m3fn_scaled.safetensors\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/Comfy-Org/Wan_2.1_ComfyUI_repackaged/resolve/main/split_files/vae/wan_2.1_vae.safetensors -d /content/ComfyUI/models/vae -o wan_2.1_vae.safetensors\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/Comfy-Org/Wan_2.1_ComfyUI_repackaged/resolve/main/split_files/clip_vision/clip_vision_h.safetensors -d /content/ComfyUI/models/clip_vision -o clip_vision_h.safetensors\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import gc\n",
        "import sys\n",
        "import random\n",
        "import os\n",
        "import imageio\n",
        "import subprocess\n",
        "from google.colab import files\n",
        "from IPython.display import display, HTML, Image as IPImage\n",
        "sys.path.insert(0, '/content/ComfyUI')\n",
        "\n",
        "from comfy import model_management\n",
        "\n",
        "from nodes import (\n",
        "    CheckpointLoaderSimple,\n",
        "    CLIPLoader,\n",
        "    CLIPTextEncode,\n",
        "    VAEDecode,\n",
        "    VAELoader,\n",
        "    KSampler,\n",
        "    UNETLoader,\n",
        "    LoadImage,\n",
        "    CLIPVisionLoader,\n",
        "    CLIPVisionEncode\n",
        ")\n",
        "\n",
        "from custom_nodes.ComfyUI_GGUF.nodes import UnetLoaderGGUF\n",
        "from comfy_extras.nodes_model_advanced import ModelSamplingSD3\n",
        "from comfy_extras.nodes_images import SaveAnimatedWEBP\n",
        "from comfy_extras.nodes_video import SaveWEBM\n",
        "from comfy_extras.nodes_wan import WanImageToVideo\n",
        "\n",
        "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
        "\n",
        "# Initialize nodes\n",
        "unet_loader = UnetLoaderGGUF()\n",
        "model_sampling = ModelSamplingSD3()\n",
        "clip_loader = CLIPLoader()\n",
        "clip_encode_positive = CLIPTextEncode()\n",
        "clip_encode_negative = CLIPTextEncode()\n",
        "vae_loader = VAELoader()\n",
        "clip_vision_loader = CLIPVisionLoader()\n",
        "clip_vision_encode = CLIPVisionEncode()\n",
        "load_image = LoadImage()\n",
        "wan_image_to_video = WanImageToVideo()\n",
        "ksampler = KSampler()\n",
        "vae_decode = VAEDecode()\n",
        "save_webp = SaveAnimatedWEBP()\n",
        "save_webm = SaveWEBM()\n",
        "\n",
        "def clear_memory():\n",
        "    gc.collect()\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n",
        "        torch.cuda.ipc_collect()\n",
        "    for obj in list(globals().values()):\n",
        "        if torch.is_tensor(obj) or (hasattr(obj, \"data\") and torch.is_tensor(obj.data)):\n",
        "            del obj\n",
        "    gc.collect()\n",
        "\n",
        "def save_as_mp4(images, filename_prefix, fps, output_dir=\"/content/ComfyUI/output\"):\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    output_path = f\"{output_dir}/{filename_prefix}.mp4\"\n",
        "\n",
        "    frames = [(img.cpu().numpy() * 255).astype(np.uint8) for img in images]\n",
        "\n",
        "    with imageio.get_writer(output_path, fps=fps) as writer:\n",
        "        for frame in frames:\n",
        "            writer.append_data(frame)\n",
        "\n",
        "    return output_path\n",
        "\n",
        "def save_as_webp(images, filename_prefix, fps, quality=90, lossless=False, method=4, output_dir=\"/content/ComfyUI/output\"):\n",
        "    \"\"\"Save images as animated WEBP using imageio.\"\"\"\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    output_path = f\"{output_dir}/{filename_prefix}.webp\"\n",
        "\n",
        "\n",
        "    frames = [(img.cpu().numpy() * 255).astype(np.uint8) for img in images]\n",
        "\n",
        "\n",
        "    kwargs = {\n",
        "        'fps': int(fps),\n",
        "        'quality': int(quality),\n",
        "        'lossless': bool(lossless),\n",
        "        'method': int(method)\n",
        "    }\n",
        "\n",
        "    with imageio.get_writer(\n",
        "        output_path,\n",
        "        format='WEBP',\n",
        "        mode='I',\n",
        "        **kwargs\n",
        "    ) as writer:\n",
        "        for frame in frames:\n",
        "            writer.append_data(frame)\n",
        "\n",
        "    return output_path\n",
        "\n",
        "def save_as_webm(images, filename_prefix, fps, codec=\"vp9\", quality=32, output_dir=\"/content/ComfyUI/output\"):\n",
        "    \"\"\"Save images as WEBM using imageio.\"\"\"\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    output_path = f\"{output_dir}/{filename_prefix}.webm\"\n",
        "\n",
        "\n",
        "    frames = [(img.cpu().numpy() * 255).astype(np.uint8) for img in images]\n",
        "\n",
        "\n",
        "    kwargs = {\n",
        "        'fps': int(fps),\n",
        "        'quality': int(quality),\n",
        "        'codec': str(codec),\n",
        "        'output_params': ['-crf', str(int(quality))]\n",
        "    }\n",
        "\n",
        "    with imageio.get_writer(\n",
        "        output_path,\n",
        "        format='FFMPEG',\n",
        "        mode='I',\n",
        "        **kwargs\n",
        "    ) as writer:\n",
        "        for frame in frames:\n",
        "            writer.append_data(frame)\n",
        "\n",
        "    return output_path\n",
        "\n",
        "def save_as_image(image, filename_prefix, output_dir=\"/content/ComfyUI/output\"):\n",
        "    \"\"\"Save single frame as PNG image.\"\"\"\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    output_path = f\"{output_dir}/{filename_prefix}.png\"\n",
        "\n",
        "    frame = (image.cpu().numpy() * 255).astype(np.uint8)\n",
        "\n",
        "    Image.fromarray(frame).save(output_path)\n",
        "\n",
        "    return output_path\n",
        "\n",
        "\n",
        "def upload_image():\n",
        "    \"\"\"Handle image upload in Colab and store in /content/ComfyUI/input/\"\"\"\n",
        "    from google.colab import files\n",
        "    import os\n",
        "    import shutil\n",
        "\n",
        "    os.makedirs('/content/ComfyUI/input', exist_ok=True)\n",
        "\n",
        "    uploaded = files.upload()\n",
        "\n",
        "    # Move each uploaded file to ComfyUI input directory\n",
        "    for filename in uploaded.keys():\n",
        "        src_path = f'/content/ComfyUI/{filename}'\n",
        "        dest_path = f'/content/ComfyUI/input/{filename}'\n",
        "\n",
        "        shutil.move(src_path, dest_path)\n",
        "        print(f\"Image saved to: {dest_path}\")\n",
        "        return dest_path\n",
        "\n",
        "    return None\n",
        "\n",
        "def generate_video(\n",
        "    image_path: str = '/content/ComfyUI/input',\n",
        "    positive_prompt: str = \"a cute anime girl with massive fennec ears and a big fluffy tail wearing a maid outfit turning around\",\n",
        "    negative_prompt: str = \"Vibrant colors, overexposed, static, blurry details, subtitles, style, artwork, painting, image, still, overall grayish, worst quality, low quality, JPEG compression residue, ugly, incomplete, extra fingers, poorly drawn hands, poorly drawn faces, deformed, disfigured, distorted limbs, fingers fused together, static image, cluttered background, three legs, many people in the background, walking backwards\",\n",
        "    #negative_prompt\n",
        "    width: int = 832,\n",
        "    height: int = 480,\n",
        "    seed: int = 82628696717253,\n",
        "    steps: int = 20,\n",
        "    cfg_scale: float = 1.0,\n",
        "    sampler_name: str = \"uni_pc\",\n",
        "    scheduler: str = \"simple\",\n",
        "    frames: int = 90,\n",
        "    fps: int = 16,\n",
        "    output_format: str = \"mp4\"\n",
        "):\n",
        "\n",
        "    with torch.inference_mode():\n",
        "        print(\"Loading Text_Encoder...\")\n",
        "        clip = clip_loader.load_clip(\"umt5_xxl_fp8_e4m3fn_scaled.safetensors\", \"wan\", \"default\")[0]\n",
        "\n",
        "        positive = clip_encode_positive.encode(clip, positive_prompt)[0]\n",
        "        negative = clip_encode_negative.encode(clip, negative_prompt)[0]\n",
        "\n",
        "        del clip\n",
        "        torch.cuda.empty_cache()\n",
        "        gc.collect()\n",
        "\n",
        "        if image_path is None:\n",
        "            print(\"Please upload an image file:\")\n",
        "            image_path = upload_image()\n",
        "        if image_path is None:\n",
        "            print(\"No image uploaded!\")\n",
        "        loaded_image = load_image.load_image(image_path)[0]\n",
        "        clip_vision = clip_vision_loader.load_clip(\"clip_vision_h.safetensors\")[0]\n",
        "        clip_vision_output = clip_vision_encode.encode(clip_vision, loaded_image, \"none\")[0]\n",
        "\n",
        "        del clip_vision\n",
        "        torch.cuda.empty_cache()\n",
        "        gc.collect()\n",
        "\n",
        "        print(\"Loading VAE...\")\n",
        "        vae = vae_loader.load_vae(\"wan_2.1_vae.safetensors\")[0]\n",
        "\n",
        "        positive_out, negative_out, latent = wan_image_to_video.encode(\n",
        "            positive, negative, vae, width, height, frames, 1, loaded_image, clip_vision_output\n",
        "        )\n",
        "\n",
        "        print(\"Loading Unet Model...\")\n",
        "        if useQ6:\n",
        "            model = unet_loader.load_unet(\"wan2.1-i2v-14b-480p-Q6_K.gguf\")[0]\n",
        "        else:\n",
        "            model = unet_loader.load_unet(\"wan2.1-i2v-14b-480p-Q4_0.gguf\")[0]\n",
        "        model = model_sampling.patch(model, 8)[0]\n",
        "\n",
        "        print(\"Generating video...\")\n",
        "        sampled = ksampler.sample(\n",
        "            model=model,\n",
        "            seed=seed,\n",
        "            steps=steps,\n",
        "            cfg=cfg_scale,\n",
        "            sampler_name=sampler_name,\n",
        "            scheduler=scheduler,\n",
        "            positive=positive_out,\n",
        "            negative=negative_out,\n",
        "            latent_image=latent\n",
        "        )[0]\n",
        "\n",
        "        del model\n",
        "        torch.cuda.empty_cache()\n",
        "        gc.collect()\n",
        "\n",
        "        try:\n",
        "            print(\"Decoding latents...\")\n",
        "            decoded = vae_decode.decode(vae, sampled)[0]\n",
        "\n",
        "            del vae\n",
        "            torch.cuda.empty_cache()\n",
        "            gc.collect()\n",
        "\n",
        "            output_path = \"\"\n",
        "            if frames == 1:\n",
        "                print(\"Single frame detected - saving as PNG image...\")\n",
        "                output_path = save_as_image(decoded[0], \"ComfyUI\")\n",
        "                # print(f\"Image saved as PNG: {output_path}\")\n",
        "\n",
        "                display(IPImage(filename=output_path))\n",
        "            else:\n",
        "                if output_format.lower() == \"webm\":\n",
        "                    print(\"Saving as WEBM...\")\n",
        "                    output_path = save_as_webm(\n",
        "                        decoded,\n",
        "                        \"ComfyUI\",\n",
        "                        fps=fps,\n",
        "                        codec=\"vp9\",\n",
        "                        quality=10\n",
        "                    )\n",
        "                elif output_format.lower() == \"mp4\":\n",
        "                    print(\"Saving as MP4...\")\n",
        "                    output_path = save_as_mp4(decoded, \"ComfyUI\", fps)\n",
        "                else:\n",
        "                    raise ValueError(f\"Unsupported output format: {output_format}\")\n",
        "\n",
        "                # print(f\"Video saved as {output_format.upper()}: {output_path}\")\n",
        "\n",
        "                display_video(output_path)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error during decoding/saving: {str(e)}\")\n",
        "            raise\n",
        "        finally:\n",
        "            clear_memory()\n",
        "\n",
        "def display_video(video_path):\n",
        "    from IPython.display import HTML\n",
        "    from base64 import b64encode\n",
        "\n",
        "    video_data = open(video_path,'rb').read()\n",
        "\n",
        "    # Determine MIME type based on file extension\n",
        "    if video_path.lower().endswith('.mp4'):\n",
        "        mime_type = \"video/mp4\"\n",
        "    elif video_path.lower().endswith('.webm'):\n",
        "        mime_type = \"video/webm\"\n",
        "    elif video_path.lower().endswith('.webp'):\n",
        "        mime_type = \"image/webp\"\n",
        "    else:\n",
        "        mime_type = \"video/mp4\"  # default\n",
        "\n",
        "    data_url = f\"data:{mime_type};base64,\" + b64encode(video_data).decode()\n",
        "\n",
        "    display(HTML(f\"\"\"\n",
        "    <video width=512 controls autoplay loop>\n",
        "        <source src=\"{data_url}\" type=\"{mime_type}\">\n",
        "    </video>\n",
        "    \"\"\"))\n",
        "\n",
        "print(\"✅ Environment Setup Complete!\")\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Generate Video\n",
        "\n",
        "positive_prompt = \"woman with her legs spread having sex with a man, rhythmic motion deep penetration fast movement back and forth, A man is thrusting his penis back and forth inside her vagina at the bottom of the screen, movement is fast, woman leans back, woman sticks her fingers in her ass while the man is still deep in her vagina\" # @param {\"type\":\"string\"}\n",
        "#negative_prompt = \"色调艳丽，过曝，静态，细节模糊不清，字幕，风格，作品，画作，画面，静止，整体发灰，最差质量，低质量，JPEG压缩残留，丑陋的，残缺的，多余的手指，画得不好的手部，画得不好的脸部，畸形的，毁容的，形态畸形的肢体，手指融合，静止不动的画面，杂乱的背景，三条腿，背景人很多，倒着走\" # @param {\"type\":\"string\"}\n",
        "negative_prompt = \"Vibrant colors, overexposed, static, blurry details, subtitles, style, artwork, painting, image, still, overall grayish, worst quality, low quality, JPEG compression residue, ugly, incomplete, extra fingers, poorly drawn hands, poorly drawn faces, deformed, disfigured, distorted limbs, fingers fused together, static image, cluttered background, three legs, many people in the background, walking backwards\" # @param {\"type\":\"string\"}\n",
        "width = 512 # @param {\"type\":\"number\"}\n",
        "height = 512 # @param {\"type\":\"number\"}\n",
        "seed = 0 # @param {\"type\":\"integer\"}\n",
        "steps = 20 # @param {\"type\":\"integer\", \"min\":1, \"max\":100}\n",
        "cfg_scale = 3 # @param {\"type\":\"number\", \"min\":1, \"max\":20}\n",
        "sampler_name = \"uni_pc\" # @param [\"uni_pc\", \"euler\", \"dpmpp_2m\", \"ddim\", \"lms\"]\n",
        "scheduler = \"simple\" # @param [\"simple\", \"normal\", \"karras\", \"exponential\"]\n",
        "frames = 75 # @param {\"type\":\"integer\", \"min\":1, \"max\":120}\n",
        "fps = 16 # @param {\"type\":\"integer\", \"min\":1, \"max\":60}\n",
        "output_format = \"webm\" # @param [\"mp4\", \"webm\"]\n",
        "\n",
        "import random\n",
        "seed = seed if seed != 0 else random.randint(0, 2**32 - 1)\n",
        "print(f\"Using seed: {seed}\")\n",
        "\n",
        "with torch.inference_mode():\n",
        "  generate_video(\n",
        "    image_path='/content/ComfyUI/input/ComfyUI_00031_.png',\n",
        "    positive_prompt=positive_prompt,\n",
        "    negative_prompt=negative_prompt,\n",
        "    width=width,\n",
        "    height=height,\n",
        "    seed=seed,\n",
        "    steps=steps,\n",
        "    cfg_scale=cfg_scale,\n",
        "    sampler_name=sampler_name,\n",
        "    scheduler=scheduler,\n",
        "    frames=frames,\n",
        "    fps=fps,\n",
        "    output_format=output_format\n",
        "  )\n",
        "clear_memory()"
      ],
      "metadata": {
        "id": "wo8w6tKerJMJ",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "YGEw9wuacjWv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Artifacts and redundant"
      ],
      "metadata": {
        "id": "qg4Hsh3iVAOe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "izNfYFufTbV9"
      },
      "outputs": [],
      "source": [
        " #@title Environment Setup\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "OPTIONS = {}\n",
        "\n",
        "USE_GOOGLE_DRIVE = True  #@param {type:\"boolean\"}\n",
        "UPDATE_COMFY_UI = False  #@param {type:\"boolean\"}\n",
        "USE_COMFYUI_MANAGER = True  #@param {type:\"boolean\"}\n",
        "INSTALL_CUSTOM_NODES_DEPENDENCIES = True  #@param {type:\"boolean\"}\n",
        "OPTIONS['USE_GOOGLE_DRIVE'] = USE_GOOGLE_DRIVE\n",
        "OPTIONS['UPDATE_COMFY_UI'] = UPDATE_COMFY_UI\n",
        "OPTIONS['USE_COMFYUI_MANAGER'] = USE_COMFYUI_MANAGER\n",
        "OPTIONS['INSTALL_CUSTOM_NODES_DEPENDENCIES'] = INSTALL_CUSTOM_NODES_DEPENDENCIES\n",
        "\n",
        "current_dir = !pwd\n",
        "WORKSPACE = f\"{current_dir[0]}/ComfyUI\"\n",
        "\n",
        "if OPTIONS['USE_GOOGLE_DRIVE']:\n",
        "    !echo \"Mounting Google Drive...\"\n",
        "    %cd /\n",
        "\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "    WORKSPACE = \"/content/drive/MyDrive/ComfyUI\"\n",
        "    %cd /content/drive/MyDrive\n",
        "\n",
        "![ ! -d $WORKSPACE ] && echo -= Initial setup ComfyUI =- && git clone https://github.com/comfyanonymous/ComfyUI\n",
        "%cd $WORKSPACE\n",
        "\n",
        "if OPTIONS['UPDATE_COMFY_UI']:\n",
        "  !echo -= Updating ComfyUI =-\n",
        "  !git pull\n",
        "\n",
        "!echo -= Install dependencies =-\n",
        "#updated 11th December 2023\n",
        "#Remove cu121 as it causes issues in Colab.\n",
        "#!pip install xformers!=0.0.18 -r requirements.txt --extra-index-url https://download.pytorch.org/whl/cu121 --extra-index-url https://download.pytorch.org/whl/cu118 --extra-index-url https://download.pytorch.org/whl/cu117\n",
        "#!pip3 install accelerate\n",
        "#!pip3 install einops transformers>=4.25.1 safetensors>=0.3.0 aiohttp pyyaml Pillow scipy tqdm psutil\n",
        "#!pip3 install xformers!=0.0.18 torch==2.1.0 torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
        "#!pip3 install torchsde\n",
        "\n",
        "#update 2025\n",
        "!echo -= Install dependencies =-\n",
        "!pip3 install accelerate\n",
        "!pip3 install einops transformers>=4.28.1 safetensors>=0.4.2 aiohttp pyyaml Pillow scipy tqdm psutil tokenizers>=0.13.3\n",
        "!pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu126\n",
        "!pip3 install torchsde\n",
        "!pip3 install kornia>=0.7.1 spandrel soundfile sentencepiece\n",
        "!pip3 install av\n",
        "\n",
        "if OPTIONS['USE_COMFYUI_MANAGER']:\n",
        "  %cd custom_nodes\n",
        "  ![ ! -d ComfyUI-Manager ] && echo -= Initial setup ComfyUI-Manager =- && git clone https://github.com/ltdrdata/ComfyUI-Manager\n",
        "  %cd ComfyUI-Manager\n",
        "  !git pull\n",
        "\n",
        "%cd $WORKSPACE\n",
        "\n",
        "if OPTIONS['INSTALL_CUSTOM_NODES_DEPENDENCIES']:\n",
        "  !pwd\n",
        "  !echo -= Install custom nodes dependencies =-\n",
        "  ![ -f \"custom_nodes/ComfyUI-Manager/scripts/colab-dependencies.py\" ] && python \"custom_nodes/ComfyUI-Manager/scripts/colab-dependencies.py\"\n",
        "print(\"\\nAll done\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jjjjjjjjjjjjjj",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title Run ComfyUI VIA CloudFlare\n",
        "!wget -P ~ https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64.deb\n",
        "!dpkg -i ~/cloudflared-linux-amd64.deb\n",
        "\n",
        "import subprocess\n",
        "import threading\n",
        "import time\n",
        "import socket\n",
        "import urllib.request\n",
        "\n",
        "def iframe_thread(port):\n",
        "  while True:\n",
        "      time.sleep(0.5)\n",
        "      sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
        "      result = sock.connect_ex(('127.0.0.1', port))\n",
        "      if result == 0:\n",
        "        break\n",
        "      sock.close()\n",
        "  print(\"\\nComfyUI finished loading, trying to launch cloudflared (if it gets stuck here cloudflared is having issues)\\n\")\n",
        "\n",
        "  p = subprocess.Popen([\"cloudflared\", \"tunnel\", \"--url\", \"http://127.0.0.1:{}\".format(port)], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
        "  for line in p.stderr:\n",
        "    l = line.decode()\n",
        "    if \"trycloudflare.com \" in l:\n",
        "      print(\"This is the URL to access ComfyUI:\", l[l.find(\"http\"):], end='')\n",
        "    #print(l, end='')\n",
        "\n",
        "\n",
        "threading.Thread(target=iframe_thread, daemon=True, args=(8188,)).start()\n",
        "\n",
        "!python main.py --dont-print-server"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kkkkkkkkkkkkkk"
      },
      "source": [
        "### Run ComfyUI with localtunnel\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jjjjjjjjjjjjj"
      },
      "outputs": [],
      "source": [
        "!npm install -g localtunnel\n",
        "\n",
        "import subprocess\n",
        "import threading\n",
        "import time\n",
        "import socket\n",
        "import urllib.request\n",
        "\n",
        "def iframe_thread(port):\n",
        "  while True:\n",
        "      time.sleep(0.5)\n",
        "      sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
        "      result = sock.connect_ex(('127.0.0.1', port))\n",
        "      if result == 0:\n",
        "        break\n",
        "      sock.close()\n",
        "  print(\"\\nComfyUI finished loading, trying to launch localtunnel (if it gets stuck here localtunnel is having issues)\\n\")\n",
        "\n",
        "  print(\"The password/enpoint ip for localtunnel is:\", urllib.request.urlopen('https://ipv4.icanhazip.com').read().decode('utf8').strip(\"\\n\"))\n",
        "  p = subprocess.Popen([\"lt\", \"--port\", \"{}\".format(port)], stdout=subprocess.PIPE)\n",
        "  for line in p.stdout:\n",
        "    print(line.decode(), end='')\n",
        "\n",
        "\n",
        "threading.Thread(target=iframe_thread, daemon=True, args=(8188,)).start()\n",
        "\n",
        "!python main.py --dont-print-server"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gggggggggg"
      },
      "source": [
        "### Run ComfyUI with colab iframe (use only in case the previous way with localtunnel doesn't work)\n",
        "\n",
        "You should see the ui appear in an iframe. If you get a 403 error, it's your firefox settings or an extension that's messing things up.\n",
        "\n",
        "If you want to open it in another window use the link.\n",
        "\n",
        "Note that some UI features like live image previews won't work because the colab iframe blocks websockets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hhhhhhhhhh"
      },
      "outputs": [],
      "source": [
        "import threading\n",
        "import time\n",
        "import socket\n",
        "def iframe_thread(port):\n",
        "  while True:\n",
        "      time.sleep(0.5)\n",
        "      sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
        "      result = sock.connect_ex(('127.0.0.1', port))\n",
        "      if result == 0:\n",
        "        break\n",
        "      sock.close()\n",
        "  from google.colab import output\n",
        "  output.serve_kernel_port_as_iframe(port, height=1024)\n",
        "  print(\"to open it in a window you can open this link here:\")\n",
        "  output.serve_kernel_port_as_window(port)\n",
        "\n",
        "threading.Thread(target=iframe_thread, daemon=True, args=(8188,)).start()\n",
        "\n",
        "!python main.py --dont-print-server"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "GbVfIg5wdAmZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "NAnEBkOGdGLL"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "L4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}